# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/02_ids_properties.ipynb.

# %% auto 0
__all__ = ['get_data_at_times', 'select_data_by_timerange', 'get_candidate_data', 'get_candidates', 'calc_candidate_duration',
           'calc_events_duration', 'calc_events_mva_features', 'calc_normal_direction', 'calc_events_normal_direction',
           'calc_events_vec_change', 'process_events']

# %% ../../../notebooks/02_ids_properties.ipynb 1
# | code-summary: "Import all the packages needed for the project"
import polars as pl
import xarray as xr
import numpy as np

try:
    import modin.pandas as pd
    from modin.config import ProgressBar

    ProgressBar.enable()
except ImportError:
    import pandas as pd

from loguru import logger

from ..propeties.duration import calc_duration
from ..propeties.mva import calc_mva_features_all
from typing import Literal

# %% ../../../notebooks/02_ids_properties.ipynb 2
def get_data_at_times(data: xr.DataArray, times) -> np.ndarray:
    """
    Select data at specified times.
    """
    # Use xarray's selection capability if data supports it
    return data.sel(time=times, method="nearest").to_numpy()


def select_data_by_timerange(data: xr.DataArray, tstart, tstop, neighbor: int = 0):
    duration = tstop - tstart
    offset = neighbor * duration
    timerange = slice(tstart - offset, tstop + offset)
    return data.sel(time=timerange)


def get_candidate_data(candidate: dict, data: xr.DataArray, **kwargs):
    return select_data_by_timerange(
        data, candidate["tstart"], candidate["tstop"], **kwargs
    )


def get_candidates(candidates: pd.DataFrame, candidate_type=None, num: int = 4):
    if candidate_type is not None:
        _candidates = candidates[candidates["type"] == candidate_type]
    else:
        _candidates = candidates

    # Sample a specific number of candidates if num is provided and it's less than the total number
    if num < len(_candidates):
        logger.info(
            f"Sampling {num} {candidate_type} candidates out of {len(_candidates)}"
        )
        return _candidates.sample(num)
    else:
        return _candidates

# %% ../../../notebooks/02_ids_properties.ipynb 4
def ld2dl(listdict: list[dict], func=np.array):
    """Convert a list of dictionaries to a dictionary of lists."""
    return {key: func([result[key] for result in listdict]) for key in listdict[0]}

# %% ../../../notebooks/02_ids_properties.ipynb 5
def calc_candidate_duration(candidate, data, **kwargs):
    candidate_data = get_candidate_data(candidate, data)
    return calc_duration(candidate_data, **kwargs)

# %% ../../../notebooks/02_ids_properties.ipynb 6
def calc_events_duration(df: pl.DataFrame, data, tr_cols=["tstart", "tstop"], **kwargs):
    # TODO: Add support for parallel processing
    results = [
        calc_duration(select_data_by_timerange(data, row[0], row[1]), **kwargs)
        for row in df.select(tr_cols).iter_rows()
    ]
    return df.with_columns(**ld2dl(results)).drop_nulls()


def calc_events_mva_features(
    df: pl.DataFrame,
    data: xr.DataArray,
    method: Literal["fit", "derivative"],
    tr_cols=["t.d_start", "t.d_end"],
    **kwargs,
):
    results = [
        calc_mva_features_all(
            select_data_by_timerange(data, row[0], row[1]), method=method, **kwargs
        )
        for row in df.select(tr_cols).iter_rows()
    ]
    return df.with_columns(**ld2dl(results))

# %% ../../../notebooks/02_ids_properties.ipynb 8
def calc_normal_direction(v1, v2, normalize=True) -> np.ndarray:
    """
    Computes the normal direction of two vectors.

    Parameters
    ----------
    v1 : array_like
        The first vector(s).
    v2 : array_like
        The second vector(s).
    """
    c = np.cross(v1, v2)
    return c / np.linalg.norm(c, axis=-1, keepdims=True)

# %% ../../../notebooks/02_ids_properties.ipynb 9
def calc_events_normal_direction(events: pl.DataFrame, data: xr.DataArray, name="k"):
    """
    Computes the normal directions(s) at two different time steps.
    """
    tstart = events["t.d_start"].to_numpy()
    tstop = events["t.d_end"].to_numpy()

    vecs_before = get_data_at_times(data, tstart)
    vecs_after = get_data_at_times(data, tstop)

    normal_directions = calc_normal_direction(vecs_before, vecs_after)
    # need to convert to list first, as only 1D array is supported
    return events.with_columns(pl.Series(name, normal_directions))

# %% ../../../notebooks/02_ids_properties.ipynb 10
def calc_events_vec_change(events: pl.DataFrame, data: xr.DataArray, name="dB"):
    """
    Utils function to calculate features related to the change of the magnetic field
    """
    tstart = events["t.d_start"].to_numpy()
    tstop = events["t.d_end"].to_numpy()

    vecs_before = get_data_at_times(data, tstart)
    vecs_after = get_data_at_times(data, tstop)
    dvecs = vecs_after - vecs_before

    return events.with_columns(pl.Series(name, dvecs))

# %% ../../../notebooks/02_ids_properties.ipynb 12
def process_events(
    events: pl.DataFrame,  # potential candidates DataFrame
    data: xr.DataArray,
    method: Literal["fit", "derivative"] = "fit",
    **kwargs,
):
    "Process candidates DataFrame"

    if method == "fit":
        duration_method = "distance"
        duration_expr = pl.col("fit.vars.sigma") * 2
    else:
        duration_method = "derivative"
        duration_expr = (
            pl.col("t.d_end") - pl.col("t.d_start")
        ).dt.total_nanoseconds() / 1e9

    return (
        events.pipe(calc_events_duration, data=data, method=duration_method)
        .pipe(calc_events_mva_features, data=data, method=method)
        .pipe(calc_events_vec_change, data=data, name="dB")
        .pipe(calc_events_normal_direction, data=data, name="k")
    ).with_columns(duration=duration_expr)
