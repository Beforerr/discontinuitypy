# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/missions/juno/mag.ipynb.

# %% auto 0
__all__ = ['JunoPhases', 'JunoFGMCoords', 'JunoFGMTimeResolutions', 'pds_download', 'download_data', 'load_data',
           'preprocess_data', 'process_data', 'create_pipeline', 'process_jno_index', 'create_jno_index_pipeline']

# %% ../../../notebooks/missions/juno/mag.ipynb 1
from datetime import timedelta
import polars as pl

from kedro.pipeline import Pipeline, node
from kedro.pipeline.modular_pipeline import pipeline

# %% ../../../notebooks/missions/juno/mag.ipynb 5
from ... import ROOT_DIR, PARAMS
import pooch
from pooch import Unzip
from ...utils.basic import load_lbl, concat_partitions
from pipe import select, filter
from typing import Literal


# %% ../../../notebooks/missions/juno/mag.ipynb 6
#| code-summary: type definitions
JunoPhases = Literal["CRUISE", "JUPITER"]
JunoFGMCoords = Literal['SE', 'SS', 'PL']
JunoFGMTimeResolutions = Literal["1SEC", "1MIN"]

# %% ../../../notebooks/missions/juno/mag.ipynb 7
def pds_download(
    mission,  # planetary missions
    instrument,
    dataset,  # Dataset may correspond to a phase of the mission
    coord,
    datatype,
    path,
) -> list[str]:
    "Downloading file from PDS server"
    pds_url = PARAMS["pds-download-url"]
    phase_url = PARAMS[mission][instrument][dataset]["url_format"]
    url = f"{pds_url}/{phase_url}/{coord}/{datatype}"

    files = pooch.retrieve(
        url=url,
        known_hash=None,
        path=path,
        processor=Unzip(
            extract_dir=f"{mission}/{instrument}/{dataset}/{coord}/{datatype}"
        ),
    )

    return files


def download_data(
    start=None,
    end=None,
    phase: JunoPhases = "CRUISE",
    coord: JunoFGMCoords = "SE",
    datatype: JunoFGMTimeResolutions = "1SEC",  # time resolution
) -> list[str]:
    return pds_download(
        mission="Juno",
        instrument="FGM",
        dataset=phase,
        coord=coord,
        datatype=datatype,
        path=ROOT_DIR / "data/01_raw/",
    )


def load_data(
    start,
    end,
    datatype: str = "1SEC",  # time resolution
) -> pl.DataFrame:
    files = download_data(start, end, datatype)

    data = pl.concat(
        files
        | filter(lambda x: x.endswith(".lbl"))
        | select(load_lbl)
        | select(pl.from_dataframe)
    )

    return data

# %% ../../../notebooks/missions/juno/mag.ipynb 9
from ...utils.basic import concat_partitions

# %% ../../../notebooks/missions/juno/mag.ipynb 10
def preprocess_data(raw_data: pl.DataFrame) -> pl.DataFrame:
    """
    Preprocess the raw dataset (only minor transformations)

    - Applying naming conventions for columns
    - Parsing and typing data
    - Changing storing format (from `lbl` to `parquet`)
    - Dropping useless columns
    """

    df_pl = (
        raw_data.lazy()
        .with_columns(time=pl.col("SAMPLE UTC").str.to_datetime("%Y %j %H %M %S %f"))
        .drop(["SAMPLE UTC", "DECIMAL DAY", "INSTRUMENT RANGE"])
        .sort("time")
        .collect()
    )
    return df_pl

# %% ../../../notebooks/missions/juno/mag.ipynb 12
from ...utils.basic import partition_data_by_year

# %% ../../../notebooks/missions/juno/mag.ipynb 13
def process_data(
    raw_data: pl.DataFrame,
    ts: str = None,  # time resolution
    coord: str = None,
) -> pl.DataFrame | dict[str, pl.DataFrame]:
    """
    Partitioning data, for the sake of memory
    """
    return partition_data_by_year(raw_data)

# %% ../../../notebooks/missions/juno/mag.ipynb 15
from ...core.pipeline import extract_features
from ..default.data_mag import create_pipeline_template


def create_pipeline(sat_id="JNO", source="MAG"):
    return create_pipeline_template(
        sat_id=sat_id,
        source=source,
        load_data_fn=load_data,
        preprocess_data_fn=preprocess_data,
        process_data_fn=process_data,
        extract_features_fn=extract_features,
    )

# %% ../../../notebooks/missions/juno/mag.ipynb 21
import pandas
import pdpipe as pdp

# %% ../../../notebooks/missions/juno/mag.ipynb 22
def process_jno_index(df: pandas.DataFrame):
    _index_time_format = "%Y-%jT%H:%M:%S.%f"

    df.columns = df.columns.str.replace(" ", "")
    jno_index_pipeline = pdp.PdPipeline(
        [
            pdp.ColDrop(["PRODUCT_ID", "CR_DATE", "PRODUCT_LABEL_MD5CHECKSUM"]),
            pdp.ApplyByCols("SID", str.rstrip),
            pdp.ApplyByCols("FILE_SPECIFICATION_NAME", str.rstrip),
            pdp.ColByFrameFunc(
                "START_TIME",
                lambda df: pandas.to_datetime(
                    df["START_TIME"], format=_index_time_format
                ),
            ),
            pdp.ColByFrameFunc(
                "STOP_TIME",
                lambda df: pandas.to_datetime(
                    df["STOP_TIME"], format=_index_time_format
                ),
            ),
            # pdp.ApplyByCols(['START_TIME', 'STOP_TIME'], pandas.to_datetime, format=_index_time_format), # NOTE: This is slow
        ]
    )

    return jno_index_pipeline(df)

# %% ../../../notebooks/missions/juno/mag.ipynb 24
from kedro.pipeline import pipeline, node

# %% ../../../notebooks/missions/juno/mag.ipynb 25
def create_jno_index_pipeline():
    jno_index_pipeline = pipeline(
        [
            node(process_jno_index, inputs="raw_JNO_SS_index", outputs="JNO_SS_index"),
            node(process_jno_index, inputs="raw_JNO_J_index", outputs="JNO_J_index"),
            node(
                lambda x1, x2: pandas.concat([x1, x2]),
                inputs=["JNO_SS_index", "JNO_J_index"],
                outputs="JNO_index",
            ),
        ]
    )
    return jno_index_pipeline
