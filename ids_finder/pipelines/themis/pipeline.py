# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/missions/03_themis.ipynb.

# %% auto 0
__all__ = ['check_dataype', 'download_mag_data', 'spz2df', 'load_mag_data', 'preprocess_mag_data', 'process_mag_data',
           'create_mag_data_pipeline', 'download_state_data', 'load_state_data', 'preprocess_state_data',
           'preprocess_sw_state_data', 'flow2gse', 'filter_tranges', 'add_state', 'process_state_data',
           'create_state_data_pipeline', 'filter_sw_events', 'create_sw_events_pipeline', 'create_pipeline']

# %% ../../../notebooks/missions/03_themis.ipynb 5
# | code-summary: import all the packages needed for the project
# | output: hide
from ...core import *
from ...utils.basic import DataConfig
from fastcore.utils import *
from fastcore.test import *

import polars as pl
import pandas
import numpy as np
import xarray as xr


from datetime import timedelta, datetime
from loguru import logger

# %% ../../../notebooks/missions/03_themis.ipynb 7
from kedro.pipeline import Pipeline, node
from kedro.pipeline.modular_pipeline import pipeline

# %% ../../../notebooks/missions/03_themis.ipynb 12
import speasy as spz
from speasy import SpeasyVariable

# %% ../../../notebooks/missions/03_themis.ipynb 13
def check_dataype(ts: int):
    ts = pandas.Timedelta(seconds=ts)
    fgs_ts = timedelta(seconds=3)
    fgl_ts = timedelta(seconds=0.1)

    if ts > fgs_ts:
        datatype = "fgs"
    elif ts > fgl_ts:
        datatype = "fgl"
    else:
        datatype = "fgh"
    return datatype

# %% ../../../notebooks/missions/03_themis.ipynb 14
def download_mag_data(
    trange, probe: str = "b", datatype="fgs", coord="gse"
) -> SpeasyVariable:
    match probe:
        case "b":
            sat = "thb"

    product = f"cda/{sat.upper()}_L2_FGM/{sat}_{datatype}_{coord}"
    data = spz.get_data(product, trange, disable_proxy=True)

    return data


def spz2df(raw_data: SpeasyVariable):
    return pl.from_dataframe(raw_data.to_dataframe().reset_index()).rename(
        {"index": "time"}
    )


def load_mag_data(
    start: str,
    end: str,
    ts: int = None,  # time resolution
    probe: str = "b",
    coord="gse",
):
    trange = [start, end]

    datatype = check_dataype(ts)

    data = download_mag_data(trange, probe, datatype, coord)
    return spz2df(data).lazy()

# %% ../../../notebooks/missions/03_themis.ipynb 16
from ...utils.basic import resample

# %% ../../../notebooks/missions/03_themis.ipynb 17
def preprocess_mag_data(
    raw_data: pl.LazyFrame,
    datatype: str = None,
    coord: str = "gse",
) -> pl.LazyFrame:
    """
    Preprocess the raw dataset (only minor transformations)

    - Applying naming conventions for columns
    - Dropping duplicate time
    - Changing storing format to `parquet`

    """

    datatype = datatype.upper()
    name_mapping = {
        f"Bx {datatype}-D": "B_x",
        f"By {datatype}-D": "B_y",
        f"Bz {datatype}-D": "B_z",
    }

    return raw_data.sort("time").unique("time").rename(name_mapping)

# %% ../../../notebooks/missions/03_themis.ipynb 19
from ...utils.basic import partition_data_by_year

# %% ../../../notebooks/missions/03_themis.ipynb 20
def process_mag_data(
    raw_data: pl.LazyFrame,
    ts: int = None,  # time resolution
) -> pl.DataFrame | Dict[str, pl.DataFrame]:
    """
    Partitioning data, for the sake of memory
    """

    every = timedelta(seconds=ts)
    period = 2 * every

    return raw_data.pipe(resample, every=every, period=period).pipe(
        partition_data_by_year
    )

# %% ../../../notebooks/missions/03_themis.ipynb 22
def create_mag_data_pipeline(
    sat_id: str,  # satellite id, used for namespace
    ts: int = 1,  # time resolution, in seconds
    tau: str = "60s",  # time window
    **kwargs,
) -> Pipeline:
    
    datatype = check_dataype(
        ts
    )  # get the datatype from the time resolution, which is reasonable but not always is the case
    ts_str = f"ts_{ts}s"

    node_load_data = node(
        load_mag_data,
        inputs=dict(
            start="params:start_date",
            end="params:end_date",
            ts="params:mag.time_resolution",
        ),
        outputs=f"raw_mag",
        name=f"load_{sat_id.upper()}_magnetic_field_data",
    )

    node_preprocess_data = node(
        preprocess_mag_data,
        inputs=dict(
            raw_data=f"raw_mag",
            datatype=datatype,
        ),
        outputs=f"inter_mag_{datatype}",
        name=f"preprocess_{sat_id.upper()}_magnetic_field_data",
    )

    node_process_data = node(
        process_mag_data,
        inputs=dict(
            raw_data=f"inter_mag_{datatype}",
            ts="params:mag.time_resolution",
        ),
        outputs=f"primary_mag_{ts_str}",
        name=f"process_{sat_id.upper()}_magnetic_field_data",
    )

    node_extract_features = node(
        extract_features,
        inputs=[f"primary_mag_{ts_str}", "params:tau", "params:mag"],
        outputs=f"feature_{ts_str}_tau_{tau}",
        name=f"extract_{sat_id}_features",
    )

    nodes = [
        node_load_data,
        node_preprocess_data,
        node_process_data,
        node_extract_features,
    ]

    pipelines = pipeline(
        nodes,
        namespace=sat_id,
        parameters={
            "params:start_date": "params:jno_start_date",
            "params:end_date": "params:jno_end_date",
            "params:tau": "params:tau",
        },
    )

    return pipelines

# %% ../../../notebooks/missions/03_themis.ipynb 28
from ...utils.basic import cdf2pl, pmap

# %% ../../../notebooks/missions/03_themis.ipynb 29
def download_state_data(
    start: str = None,
    end: str = None,
    ts: str = None,  # time resolution
    probe: str = None,
    coord: str = None,
):
    import pyspedas

    trange = [start, end]
    files = pyspedas.omni.data(trange=trange, datatype="hour", downloadonly=True)
    return files


def load_state_data(
    start: str = None,
    end: str = None,
    ts: str = None,  # time resolution
    vars: dict = None,
):
    files = download_state_data(start, end, ts, vars)
    df: pl.LazyFrame = pl.concat(files | pmap(cdf2pl, var_names=list(vars)))
    return df

# %% ../../../notebooks/missions/03_themis.ipynb 31
def preprocess_state_data(
    raw_data: pl.LazyFrame,
    vars: dict,
) -> pl.LazyFrame:
    """
    Preprocess the raw dataset (only minor transformations)

    - Applying naming conventions for columns
    - Extracting variables from `CDF` files, and convert them to DataFrame
    """

    columns_name_mapping = {key: value["COLNAME"] for key, value in vars.items()}

    return raw_data.rename(columns_name_mapping)

# %% ../../../notebooks/missions/03_themis.ipynb 33
def preprocess_sw_state_data(
    raw_data: pandas.DataFrame,
) -> pl.LazyFrame:
    """
    - Applying naming conventions for columns
    - Parsing and typing data (like from string to datetime for time columns)
    """

    return pl.from_dataframe(raw_data).with_columns(
        # Note: For `polars`, please either specify both hour and minute, or neither.
        pl.concat_str(pl.col("start"), pl.lit(" 00")).str.to_datetime(
            format="%Y %j %H %M"
        ),
        pl.concat_str(pl.col("end"), pl.lit(" 00")).str.to_datetime(
            format="%Y %j %H %M"
        ),
    )

# %% ../../../notebooks/missions/03_themis.ipynb 35
def flow2gse(df: pl.LazyFrame) -> pl.LazyFrame:
    """
    - Transforming solar wind data from `Quasi-GSE` coordinate to GSE coordinate system
    """
    plasma_speed = pl.col("plasma_speed")
    sw_theta = pl.col("sw_vel_theta")
    sw_phi = pl.col("sw_vel_phi")

    return df.with_columns(
        sw_vel_gse_x=-plasma_speed * sw_theta.cos() * sw_phi.cos(),
        sw_vel_gse_y=+plasma_speed * sw_theta.cos() * sw_phi.sin(),
        sw_vel_gse_z=+plasma_speed * sw_theta.sin(),
    ).drop(["sw_theta", "sw_phi"])


def filter_tranges(time: pl.Series, tranges: Tuple[list, list]):
    """
    - Filter data by time ranges, return the indices of the time that are in the time ranges
    """

    starts = tranges[0]
    ends = tranges[1]

    start_indices = time.search_sorted(starts)
    end_indices = time.search_sorted(ends)

    return np.concatenate(
        [
            np.arange(start_index, end_index + 1)
            for start_index, end_index in zip(start_indices, end_indices)
        ]
    )


def add_state(l_df: pl.LazyFrame, l_state: pl.LazyFrame):
    state = l_state.collect()
    df = l_df.collect()

    start = state.get_column("start")
    end = state.get_column("end")

    time = df.get_column("time")

    indices = filter_tranges(time, (start, end))

    return (
        df.with_row_count()
        .with_columns(
            state=pl.when(pl.col("row_nr").is_in(indices)).then(1).otherwise(0)
        )
        .drop("row_nr")
    )


def process_state_data(df: pl.LazyFrame, state: pl.LazyFrame = None) -> pl.LazyFrame:
    """
    - Transforming data to GSE coordinate system
    - Combine state data with additional plasma state data
    """

    return (
        df.pipe(flow2gse)
        .pipe(add_state, state)
        .rename(
            {
                "sw_vel_gse_x": "v_x",
                "sw_vel_gse_y": "v_y",
                "sw_vel_gse_z": "v_z",
            }
        )
    )

# %% ../../../notebooks/missions/03_themis.ipynb 37
def create_state_data_pipeline(
    sat_id,
    ts: str = "1h",  # time resolution
) -> Pipeline:
    node_load_data = node(
        load_state_data,
        inputs=dict(
            start="params:start_date",
            end="params:end_date",
            vars="params:omni_vars",
        ),
        outputs=f"raw_state",
        name=f"load_{sat_id.upper()}_state_data",
    )

    node_preprocess_data = node(
        preprocess_state_data,
        inputs=dict(
            raw_data=f"raw_state",
            vars="params:omni_vars",
        ),
        outputs=f"inter_state_{ts}",
        name=f"preprocess_{sat_id.upper()}_state_data",
    )

    node_preprocess_sw_state = node(
        preprocess_sw_state_data,
        inputs=f"raw_state_sw",
        outputs=f"inter_state_sw",
        name=f"preprocess_{sat_id.upper()}_solar_wind_state_data",
    )

    node_process_data = node(
        process_state_data,
        inputs=[f"inter_state_{ts}", f"inter_state_sw"],
        outputs=f"primary_state_{ts}",
        name=f"process_{sat_id.upper()}_state_data",
    )

    nodes = [
        node_load_data,
        node_preprocess_data,
        node_preprocess_sw_state,
        node_process_data,
    ]
    pipelines = pipeline(
        nodes,
        namespace=sat_id,
        parameters={
            "params:omni_vars": "params:omni_vars",
            "params:start_date": "params:jno_start_date",
            "params:end_date": "params:jno_end_date",
        },
    )

    return pipelines

# %% ../../../notebooks/missions/03_themis.ipynb 40
from ..default import create_candidate_pipeline

# %% ../../../notebooks/missions/03_themis.ipynb 41
from ...utils.basic import filter_tranges_df

def filter_sw_events(events: pl.LazyFrame, sw_state: pl.LazyFrame) -> pl.LazyFrame:
    
    start, end = sw_state.select(['start', 'end']).collect()
    sw_events = filter_tranges_df(events.collect(), (start, end))
    
    return sw_events

def create_sw_events_pipeline(
    sat_id,
    tau: int = 60,
    ts_mag: int = 1,
    
):
  
    ts_mag_str = f"ts_{ts_mag}s"
    tau_str = f"tau_{tau}s"
    
    node_filter_sw_events = node(
        filter_sw_events,
        inputs=[
            f"candidates.{sat_id}_{ts_mag_str}_{tau_str}",
            f"{sat_id}.inter_state_sw",
        ],
        outputs=f"events.sw.{sat_id}_{ts_mag_str}_{tau_str}"
        
    )

    nodes = [node_filter_sw_events]
    return pipeline(nodes)

# %% ../../../notebooks/missions/03_themis.ipynb 42
def create_pipeline(
    sat_id="thb",
    tau=60, # time window, in seconds
    ts_state="1h",  # time resolution of state data
    ts_mag = 1, # time resolution of mag data, in seconds
) -> Pipeline:
    return (
        create_mag_data_pipeline(sat_id, tau=tau)
        + create_state_data_pipeline(sat_id, ts=ts_state)
        + create_candidate_pipeline(sat_id, tau=tau, ts_mag= ts_mag, ts_state=ts_state)
        + create_sw_events_pipeline(sat_id, tau=tau, ts_mag= ts_mag)
    )
