# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/pipelines/1_data.ipynb.

# %% auto 0
__all__ = ['process_data', 'extract_features', 'create_pipeline']

# %% ../../../notebooks/pipelines/1_data.ipynb 1
import polars as pl

from kedro.pipeline import Pipeline, node
from kedro.pipeline.modular_pipeline import pipeline

from typing import Any, Dict

# %% ../../../notebooks/pipelines/1_data.ipynb 9
def process_data(
    raw_data: Any | pl.DataFrame,
    ts: str = None,  # time resolution
    coord: str = None,
) -> pl.DataFrame | Dict[str, pl.DataFrame]:
    """
    Corresponding to primary data layer, where source data models are transformed into domain data models

    - Transforming coordinate system if needed
    - Smoothing data
    - Resampling data to a given time resolution
    - Partitioning data, for the sake of memory
    """
    pass

def extract_features():
    pass

# %% ../../../notebooks/pipelines/1_data.ipynb 13
def create_pipeline(
    sat_id: str,  # satellite id, used for namespace
    source: str,  # source data, like "mag" or "plasma"
    ts = 1, # time resolution, in seconds
    tau = 60, # time resolution, in seconds
    **kwargs,
) -> Pipeline:
    
    params = load_param(project_path = '../../')
    
    ts_str = f"ts_{ts}s"
    tau_str = f"tau_{tau}s"
    sat_id = sat_id.upper()
    namespace = sat_id + "." + source
    
    node_load_data = node(
        load_data,
        inputs=dict(
            start="params:start_date",
            end="params:end_date",
            ts=ts,
        ),
        outputs="raw_data",
        name="load_data",
    )

    node_preprocess_data = node(
        preprocess_data,
        inputs=dict(
            raw_data="raw_data",
            start="params:start_date",
            end="params:end_date",
        ),
        outputs=f"inter_mag_{ts_str}",
        name="preprocess_data",
    )

    node_process_data = node(
        process_data,
        inputs=f"inter_mag_{ts_str}",
        outputs=f"primary_mag_{ts_str}",
        name="process_data",
    )

    node_extract_features = node(
        extract_features,
        inputs=[f"primary_mag_{ts_str}", "params:tau", "params:extract_params"],
        outputs=f"feature_tau_{tau_str}",
        name=f"extract_{sat_id}_features",
    )

    nodes = [
        node_load_data,
        node_preprocess_data,
        node_process_data,
        node_extract_features,
    ]

    pipelines = pipeline(
        nodes,
        namespace=namespace,
        parameters={
            "params:start_date": "params:jno_start_date",
            "params:end_date": "params:jno_end_date",
            "params:tau": tau_str,
        },
    )

    return pipelines
