# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/missions/wind/index.ipynb.

# %% auto 0
__all__ = ['download_mag_data', 'load_mag_data', 'process_mag_data', 'create_pipeline']

# %% ../../../notebooks/missions/wind/index.ipynb 5
import polars as pl

# %% ../../../notebooks/missions/wind/index.ipynb 9
import pyspedas
from ...utils.basic import cdf2pl, pmap, resample

# %% ../../../notebooks/missions/wind/index.ipynb 10
def download_mag_data(trange: list[str], datatype) -> list[str]:
    files = pyspedas.wind.mfi(trange, datatype=datatype, downloadonly=True)
    return files

def load_mag_data(
    start: str = None,
    end: str = None,
    trange: list[str] = None,
    datatype="h4-rtn",
):
    if trange is None:
        trange = [start, end]

    files = download_mag_data(trange=trange, datatype=datatype)
    var_names = ["BRTN", "BF1"]
    df: pl.LazyFrame = pl.concat(files | pmap(cdf2pl, var_names=var_names))

    return df

# %% ../../../notebooks/missions/wind/index.ipynb 12
from datetime import timedelta
from ...utils.basic import partition_data_by_year

# %% ../../../notebooks/missions/wind/index.ipynb 13
def process_mag_data(
    raw_data: pl.LazyFrame,
    ts: str = None,  # time resolution
    coord: str = None,
):
    """
    Corresponding to primary data layer, where source data models are transformed into domain data models

    - Partitioning data, for the sake of memory
    """
    
    every = timedelta(seconds=ts)
    period = 2 * every
    
    return partition_data_by_year(raw_data)

# %% ../../../notebooks/missions/wind/index.ipynb 14
def create_pipeline(
    sat_id="sta",
    tau="60s",
    ts_mag="1s",  # time resolution of magnetic field data
    ts_state="1h",  # time resolution of state data
    **kwargs
):
    pass
