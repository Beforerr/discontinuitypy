# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/missions/stereo/mag.ipynb.

# %% auto 0
__all__ = ['download_data', 'load_data', 'preprocess_data', 'process_data', 'create_pipeline']

# %% ../../../notebooks/missions/stereo/mag.ipynb 1
from datetime import timedelta

import polars as pl

from ... import PARAMS
from ...utils.basic import cdf2pl, pmap, resample, partition_data_by_year
from ..default.data_mag import create_pipeline_template

from typing import Iterable

# %% ../../../notebooks/missions/stereo/mag.ipynb 4
from pathlib import Path
import os

os.environ['SPEDAS_DATA_DIR'] = str(Path.home() / 'data')
import pyspedas

# %% ../../../notebooks/missions/stereo/mag.ipynb 5
def download_data(
    start,
    end,
    probe: str = "a",
    datatype = '8hz',
) -> Iterable[str]:
    "List of CDF files"
    trange = [start, end]
    files = pyspedas.stereo.mag(trange, probe=probe, datatype=datatype, downloadonly=True)
    return files


def load_data(
    start,
    end,
    datatype = '8hz',
    probe: str = "a",
):
    files = download_data(start, end, probe, datatype)
    var_names="BFIELD"
    return pl.concat(files | pmap(cdf2pl, var_names=var_names))


# %% ../../../notebooks/missions/stereo/mag.ipynb 7
def preprocess_data(
    raw_data: pl.LazyFrame,
):
    """
    Preprocess the raw dataset (only minor transformations)
    - Applying naming conventions for columns
    """

    bcols = PARAMS["STEREO"]["MAG"]["bcols"]

    name_mapping = {
        "BFIELD_0": bcols[0],
        "BFIELD_1": bcols[1],
        "BFIELD_2": bcols[2],
    }

    return raw_data.rename(name_mapping)

# %% ../../../notebooks/missions/stereo/mag.ipynb 9
def process_data(
    raw_data: pl.DataFrame,
    ts = None,  # time resolution, in seconds
):
    every = timedelta(seconds=ts)
    period = 2 * every

    return raw_data.pipe(resample, every=every, period=period).pipe(
        partition_data_by_year
    )

# %% ../../../notebooks/missions/stereo/mag.ipynb 11
def create_pipeline(sat_id="STA", source="MAG"):
    return create_pipeline_template(
        sat_id=sat_id,
        source=source,
        load_data_fn=load_data,
        preprocess_data_fn=preprocess_data,
        process_data_fn=process_data,
    )
