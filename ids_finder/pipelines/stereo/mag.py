# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../notebooks/missions/stereo/mag.ipynb.

# %% auto 0
__all__ = ['download_data', 'load_data', 'preprocess_data', 'process_data', 'create_pipeline']

# %% ../../../notebooks/missions/stereo/mag.ipynb 1
from datetime import timedelta

import polars as pl
import pandas

from kedro.pipeline import Pipeline, node
from kedro.pipeline.modular_pipeline import pipeline

from typing import Iterable


# %% ../../../notebooks/missions/stereo/mag.ipynb 4
import os
os.environ['SPEDAS_DATA_DIR'] = f"{os.environ['HOME']}/data"
import pyspedas

# %% ../../../notebooks/missions/stereo/mag.ipynb 5
from ...utils.basic import cdf2pl, pmap

def download_data(
    start,
    end,
    probe: str = "a",
    datatype = None,
) -> Iterable[str]:
    "List of CDF files"
    trange = [start, end]
    files = pyspedas.stereo.mag(trange, probe=probe, datatype=datatype, downloadonly=True)
    return files


def load_data(
    start,
    end,
    datatype = None,
    probe: str = "a",
):
    data = download_data(start, end, probe, datatype)
    return pl.concat(data | pmap(cdf2pl, var_name="BFIELD"))


# %% ../../../notebooks/missions/stereo/mag.ipynb 7
from ...utils.basic import resample
from pipe import select

# %% ../../../notebooks/missions/stereo/mag.ipynb 8
def preprocess_data(
    raw_data: pl.LazyFrame,
    ts: str = "1s",  # time resolution
) -> pl.DataFrame:
    """
    Preprocess the raw dataset (only minor transformations)

    - Downsample the data to a given time resolution
    - Applying naming conventions for columns
    """
    every = pandas.Timedelta(ts)
    period = 2 * every

    return (
        raw_data.pipe(resample, every=every, period=period)
        .rename(
            {
                "BFIELD_0": "b_r",
                "BFIELD_1": "b_t",
                "BFIELD_2": "b_n",
                "BFIELD_3": "b_mag",
            }
        )
        .collect()
    )

# %% ../../../notebooks/missions/stereo/mag.ipynb 10
from ...utils.basic import partition_data_by_year

# %% ../../../notebooks/missions/stereo/mag.ipynb 11
def process_data(
    raw_data: pl.DataFrame,
    ts: str = None,  # time resolution
    coord: str = None,
) -> dict[str, pl.DataFrame]:
    """
    Corresponding to primary data layer, where source data models are transformed into domain data models

    - Partitioning data, for the sake of memory
    """
    return partition_data_by_year(raw_data)

# %% ../../../notebooks/missions/stereo/mag.ipynb 13
from ...core import extract_features
from ..default.data_mag import create_pipeline_template


def create_pipeline(sat_id="STA", source="MAG"):
    return create_pipeline_template(
        sat_id=sat_id,
        source=source,
        load_data_fn=load_data,
        preprocess_data_fn=preprocess_data,
        process_data_fn=process_data,
        extract_features_fn=extract_features,
    )
