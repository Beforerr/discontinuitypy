{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: IDs from ARTHEMIS\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "output-file: artemis.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "ARTEMIS spacecrafts will be exposed in the solar wind at 1 AU during its orbits around the Moon. So it's very interesting to look into its data.\n",
    "\n",
    "- For time inteval for THEMIS-B in solar wind, see [Link](https://omniweb.gsfc.nasa.gov/ftpbrowser/themis_b_sw.txt)\n",
    "- For time inteval for THEMIS-C in solar wind, see [Link](https://omniweb.gsfc.nasa.gov/ftpbrowser/themis_c_sw.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to run command in shell first as `pipeline` is project-specific command\n",
    "\n",
    "```{sh}\n",
    "kedro pipeline create themis\n",
    "```\n",
    "\n",
    "To get candidates data, run `kedro run --from-inputs=jno.feature_1s --to-outputs=candidates.jno_1s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/themis/pipeline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: import all the packages needed for the project\n",
    "#| output: hide\n",
    "#| export\n",
    "\n",
    "from ids_finder.core import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "\n",
    "import polars as pl\n",
    "import pandas\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "from loguru import logger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Kerdo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from ids_finder.utils.basic import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/18/23 14:15:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:jno_start_date'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>       <a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/18/23 14:15:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:jno_start_date'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m       \u001b]8;id=228651;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=854180;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:jno_end_date'</span> <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:jno_end_date'\u001b[0m \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m         \u001b]8;id=288760;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=854247;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catalog = load_catalog()\n",
    "\n",
    "jno_start_date = catalog.load('params:jno_start_date')\n",
    "jno_end_date = catalog.load('params:jno_end_date')\n",
    "trange = [jno_start_date, jno_end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artemis_probes = [\"b\", \"c\"]\n",
    "probe = artemis_probes[0]\n",
    "\n",
    "jno_start_date = \"2011-08-25\"\n",
    "jno_end_date = \"2016-06-30\" \n",
    "\n",
    "trange = [jno_start_date, jno_end_date]\n",
    "test_trange = [\"2011-08-25\", \"2011-09-25\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnetic field data pipeline\n",
    "\n",
    "- For convenience, we choose magnetic field data in **GSE** coordinate system\n",
    "- The `fgs` data are in 3-4s resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def download_mag_data(\n",
    "    start: str, end: str, probe: str = \"b\", datatype=\"fgs\", coord=\"gse\"\n",
    "):\n",
    "    import speasy as spz\n",
    "\n",
    "    trange = [start, end]\n",
    "\n",
    "    match probe:\n",
    "        case \"b\":\n",
    "            sat = \"thb\"\n",
    "\n",
    "    product = f\"cda/{sat.upper()}_L2_FGM/{sat}_{datatype}_{coord}\"\n",
    "    data = spz.get_data(product, trange, disable_proxy=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def spz2parquet(raw_data):\n",
    "    return pl.from_dataframe(raw_data.to_dataframe().reset_index()).rename({\"index\": \"time\"})\n",
    "\n",
    "\n",
    "def preprocess_mag_data(\n",
    "    raw_data,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = 'gse',\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Changing storing format to `parquet`\n",
    "    \"\"\"\n",
    "    return spz2parquet(raw_data).rename({\n",
    "        'Bx FGS-D': 'b_{coord}_x',\n",
    "        'By FGS-D': 'b_{coord}_y',\n",
    "        'Bz FGS-D': 'b_{coord}_z',\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from ids_finder.utils.basic import partition_data_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_mag_data(\n",
    "    raw_data: pl.DataFrame,\n",
    "    ts: str = None,  # time resolution\n",
    ") -> pl.DataFrame | Dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Partitioning data, for the sake of memory\n",
    "    \"\"\"\n",
    "    return partition_data_by_year(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def create_mag_data_pipeline(\n",
    "    sat_id: str,  # satellite id, used for namespace\n",
    "    ts: str = '4s',  # time resolution,\n",
    "    tau: str = '60s',  # time window\n",
    "    **kwargs,\n",
    ") -> Pipeline:\n",
    "    \n",
    "    node_download_data = node(\n",
    "        download_mag_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"raw_mag\",\n",
    "        name=f\"download_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_mag_data,\n",
    "        inputs=dict(\n",
    "            raw_data=f\"raw_mag\",\n",
    "        ),\n",
    "        outputs=f\"inter_mag_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_process_data = node(\n",
    "        process_mag_data,\n",
    "        inputs=f\"inter_mag_{ts}\",\n",
    "        outputs=f\"primary_mag_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_extract_features = node(\n",
    "        extract_features,\n",
    "        inputs=[f\"primary_mag_{ts}\", \"params:tau\", \"params:extract_params\"],\n",
    "        outputs=f\"feature_tau_{tau}\",\n",
    "        name=f\"extract_{sat_id}_features\",\n",
    "    )\n",
    "\n",
    "    nodes = [\n",
    "        node_download_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "        node_extract_features,\n",
    "    ]\n",
    "\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "            \"params:tau\": tau,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State data pipeline\n",
    "\n",
    "We use low resolution [OMNI data](https://omniweb.gsfc.nasa.gov/ow.html) for plasma state data, see [details](https://spdf.gsfc.nasa.gov/pub/data/omni/low_res_omni/omni2.text).\n",
    "\n",
    "- Data gaps were filled with dummy numbers for the missing hours or entire\n",
    "  days to make all files of equal length.  The character '9' is used to\n",
    "  fill all fields for missing data according to their format, e.g.\n",
    "  ' 9999.9' for a field with the FORTRAN format F7.1. Note that format F7.1\n",
    "  below really means (1X,F6.1),etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The flow OMNI \"phi\" angle is opposite GSE \"phi\" angle, threrfore, Flow-vector cartesian components in GSE coordinates may be derived from the given speed and angles as\n",
    "\n",
    "Vx = - V * cos(theta) * cos(phi)\n",
    "Vy = + V * cos(theta) * sin(phi)\n",
    "Vz = + V * sin(theta)\n",
    "and vise versa: two angles may be derived from the given speed and Vx,Vy,Vz comp. as  \n",
    "          a_theta=vz/V\n",
    "          theta=(180.*asin(a_theta))/!PI\n",
    "         a_phi=Vy/(-Vx)\n",
    "        phi=(180.*atan(a_phi))/!PI\n",
    "```\n",
    "\n",
    "```\n",
    "   (*)   Quasi-GSE for the flow longitude angle means the angle increases from zero\n",
    "         to positive values as the flow changes from being aligned along the -X(GSE)\n",
    "         axis towards the +Y(GSE) axis.  The flow longitude angle is positive for \n",
    "         flow from west of the sun, towards +Y(GSE).\n",
    "         The flow latitude angle is positive for flow from south of the sun, \n",
    "         towards +Z(GSE)\n",
    "``````                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "):\n",
    "    import pyspedas\n",
    "    \n",
    "    trange = [start, end]\n",
    "    files = pyspedas.omni.data(trange=trange, datatype='hour', downloadonly=True)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.basic import cdf2pl, pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_state_data(\n",
    "    raw_data: List[str], # files\n",
    "    vars: dict,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Extracting variables from `CDF` files, and convert them to DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    columns_name_mapping = {key: value[\"COLNAME\"] for key, value in vars.items()}\n",
    "    df: pl.LazyFrame = pl.concat(raw_data | pmap(cdf2pl, var_names=list(vars)))\n",
    "\n",
    "    return df.collect().rename(columns_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def flow2gse(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    - Transforming data from `Quasi-GSE` coordinate to GSE coordinate system\n",
    "    \"\"\"\n",
    "    sw_speed = pl.col(\"sw_speed\")\n",
    "    sw_theta = pl.col(\"sw_vel_theta\")\n",
    "    sw_phi = pl.col(\"sw_vel_phi\")\n",
    "\n",
    "    return df.with_columns(\n",
    "        sw_vel_gse_x=-sw_speed * sw_theta.cos() * sw_phi.cos(),\n",
    "        sw_vel_gse_y=+sw_speed * sw_theta.cos() * sw_phi.sin(),\n",
    "        sw_vel_gse_z=+sw_speed * sw_theta.sin(),\n",
    "    ).drop([\"sw_theta\", \"sw_phi\"])\n",
    "\n",
    "def process_state_data(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    - Transforming data to GSE coordinate system\n",
    "    \"\"\"\n",
    "\n",
    "    return df.pipe(flow2gse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_state_data_pipeline(\n",
    "    sat_id,\n",
    "    ts: str = '1h',  # time resolution\n",
    "    **kwargs\n",
    ") -> Pipeline:\n",
    "    \n",
    "    node_download_data = node(\n",
    "        download_state_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"raw_state_files\",\n",
    "        name=f\"download_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_state_data,\n",
    "        inputs=dict(\n",
    "            raw_data=f\"raw_state_files\",\n",
    "            vars=\"params:omni_vars\",\n",
    "        ),\n",
    "        outputs=f\"inter_state_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    node_process_data = node(\n",
    "        process_state_data,\n",
    "        inputs=f\"inter_state_{ts}\",\n",
    "        outputs=f\"primary_state_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    nodes = [\n",
    "        node_download_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "    ]\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:omni_vars\": \"params:omni_vars\",\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.candidates import create_candidate_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_pipeline(\n",
    "    sat_id=\"thb\",\n",
    "    tau=\"60s\",\n",
    "    ts_state=\"1h\",  # time resolution of state data\n",
    ") -> Pipeline:\n",
    "    return (\n",
    "        create_mag_data_pipeline(sat_id, tau=tau)\n",
    "        + create_state_data_pipeline(sat_id, ts=ts_state)\n",
    "        + create_candidate_pipeline(sat_id, tau=tau, ts_state=ts_state)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">18-Oct-23 01:09:49 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>-Oct-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">01:09:49</span>: Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'thb.primary_state_1h'</span>        <a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                   </span>         <span style=\"font-weight: bold\">(</span>PolarsDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m18-Oct-23 01:09:49\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;36m18\u001b[0m-Oct-\u001b[1;36m23\u001b[0m \u001b[1;92m01:09:49\u001b[0m: Loading data from \u001b[32m'thb.primary_state_1h'\u001b[0m        \u001b]8;id=714217;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=217388;file:///Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages/kedro/io/data_catalog.py#492\u001b\\\u001b[2m492\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                   \u001b[0m         \u001b[1m(\u001b[0mPolarsDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                                                  \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>time</th><th>sw_density</th><th>sw_temperature</th><th>sw_speed</th><th>sw_vel_theta</th><th>sw_vel_phi</th><th>sw_vel_gse_x</th><th>sw_vel_gse_y</th><th>sw_vel_gse_z</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;43848&quot;</td><td>43848.0</td><td>43848.0</td><td>43848.0</td><td>43848.0</td><td>43848.0</td><td>43848.0</td><td>43848.0</td><td>43848.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>445.0</td><td>76.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>6.110902</td><td>85933.265625</td><td>412.241852</td><td>-0.790534</td><td>-0.118984</td><td>-9.411859</td><td>-3.740302</td><td>-38.05085</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>4.929866</td><td>83964.515625</td><td>87.505905</td><td>2.413519</td><td>2.73037</td><td>210.468213</td><td>210.310608</td><td>295.848938</td></tr><tr><td>&quot;min&quot;</td><td>&quot;2011-07-01 00:…</td><td>0.1</td><td>3299.0</td><td>240.0</td><td>-14.9</td><td>-26.9</td><td>-784.168997</td><td>-724.554749</td><td>-773.737244</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>3.1</td><td>35276.0</td><td>348.0</td><td>-2.2</td><td>-1.8</td><td>-154.582172</td><td>-148.638458</td><td>-299.854858</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>4.8</td><td>63350.0</td><td>396.0</td><td>-0.8</td><td>-0.2</td><td>-6.642112</td><td>0.0</td><td>-72.535683</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>7.5</td><td>107588.0</td><td>459.0</td><td>0.7</td><td>1.5</td><td>131.584089</td><td>137.39772</td><td>235.292801</td></tr><tr><td>&quot;max&quot;</td><td>&quot;2016-06-30 23:…</td><td>137.199997</td><td>1.901074e6</td><td>878.0</td><td>21.0</td><td>24.6</td><td>753.76094</td><td>868.656555</td><td>770.671265</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "\n",
       "shape: \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ describe  ┆ time      ┆ sw_densit ┆ sw_temper ┆ … ┆ sw_vel_ph ┆ sw_vel_gs ┆ sw_vel_gs ┆ sw_vel_g │\n",
       "│ ---       ┆ ---       ┆ y         ┆ ature     ┆   ┆ i         ┆ e_x       ┆ e_y       ┆ se_z     │\n",
       "│ str       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ \u001b[1;36m43848\u001b[0m     ┆ \u001b[1;36m43848.0\u001b[0m   ┆ \u001b[1;36m43848.0\u001b[0m   ┆ … ┆ \u001b[1;36m43848.0\u001b[0m   ┆ \u001b[1;36m43848.0\u001b[0m   ┆ \u001b[1;36m43848.0\u001b[0m   ┆ \u001b[1;36m43848.0\u001b[0m  │\n",
       "│ null_coun ┆ \u001b[1;36m0\u001b[0m         ┆ \u001b[1;36m445.0\u001b[0m     ┆ \u001b[1;36m76.0\u001b[0m      ┆ … ┆ \u001b[1;36m5.0\u001b[0m       ┆ \u001b[1;36m5.0\u001b[0m       ┆ \u001b[1;36m5.0\u001b[0m       ┆ \u001b[1;36m5.0\u001b[0m      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ null      ┆ \u001b[1;36m6.110902\u001b[0m  ┆ \u001b[1;36m85933.265\u001b[0m ┆ … ┆ \u001b[1;36m-0.118984\u001b[0m ┆ \u001b[1;36m-9.411859\u001b[0m ┆ \u001b[1;36m-3.740302\u001b[0m ┆ \u001b[1;36m-38.0508\u001b[0m │\n",
       "│           ┆           ┆           ┆ \u001b[1;36m625\u001b[0m       ┆   ┆           ┆           ┆           ┆ \u001b[1;36m5\u001b[0m        │\n",
       "│ std       ┆ null      ┆ \u001b[1;36m4.929866\u001b[0m  ┆ \u001b[1;36m83964.515\u001b[0m ┆ … ┆ \u001b[1;36m2.73037\u001b[0m   ┆ \u001b[1;36m210.46821\u001b[0m ┆ \u001b[1;36m210.31060\u001b[0m ┆ \u001b[1;36m295.8489\u001b[0m │\n",
       "│           ┆           ┆           ┆ \u001b[1;36m625\u001b[0m       ┆   ┆           ┆ \u001b[1;36m3\u001b[0m         ┆ \u001b[1;36m8\u001b[0m         ┆ \u001b[1;36m38\u001b[0m       │\n",
       "│ min       ┆ \u001b[1;36m2011\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m0\u001b[0m ┆ \u001b[1;36m0.1\u001b[0m       ┆ \u001b[1;36m3299.0\u001b[0m    ┆ … ┆ \u001b[1;36m-26.9\u001b[0m     ┆ \u001b[1;36m-784.1689\u001b[0m ┆ \u001b[1;36m-724.5547\u001b[0m ┆ \u001b[1;36m-773.737\u001b[0m │\n",
       "│           ┆ \u001b[1;36m1\u001b[0m         ┆           ┆           ┆   ┆           ┆ \u001b[1;36m97\u001b[0m        ┆ \u001b[1;36m49\u001b[0m        ┆ \u001b[1;36m244\u001b[0m      │\n",
       "│           ┆ \u001b[1;92m00:00:00\u001b[0m  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ \u001b[1;36m25\u001b[0m%       ┆ null      ┆ \u001b[1;36m3.1\u001b[0m       ┆ \u001b[1;36m35276.0\u001b[0m   ┆ … ┆ \u001b[1;36m-1.8\u001b[0m      ┆ \u001b[1;36m-154.5821\u001b[0m ┆ \u001b[1;36m-148.6384\u001b[0m ┆ \u001b[1;36m-299.854\u001b[0m │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ \u001b[1;36m72\u001b[0m        ┆ \u001b[1;36m58\u001b[0m        ┆ \u001b[1;36m858\u001b[0m      │\n",
       "│ \u001b[1;36m50\u001b[0m%       ┆ null      ┆ \u001b[1;36m4.8\u001b[0m       ┆ \u001b[1;36m63350.0\u001b[0m   ┆ … ┆ \u001b[1;36m-0.2\u001b[0m      ┆ \u001b[1;36m-6.642112\u001b[0m ┆ \u001b[1;36m0.0\u001b[0m       ┆ \u001b[1;36m-72.5356\u001b[0m │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ \u001b[1;36m83\u001b[0m       │\n",
       "│ \u001b[1;36m75\u001b[0m%       ┆ null      ┆ \u001b[1;36m7.5\u001b[0m       ┆ \u001b[1;36m107588.0\u001b[0m  ┆ … ┆ \u001b[1;36m1.5\u001b[0m       ┆ \u001b[1;36m131.58408\u001b[0m ┆ \u001b[1;36m137.39772\u001b[0m ┆ \u001b[1;36m235.2928\u001b[0m │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ \u001b[1;36m9\u001b[0m         ┆           ┆ \u001b[1;36m01\u001b[0m       │\n",
       "│ max       ┆ \u001b[1;36m2016\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m3\u001b[0m ┆ \u001b[1;36m137.19999\u001b[0m ┆ \u001b[1;36m1.\u001b[0m901074e ┆ … ┆ \u001b[1;36m24.6\u001b[0m      ┆ \u001b[1;36m753.76094\u001b[0m ┆ \u001b[1;36m868.65655\u001b[0m ┆ \u001b[1;36m770.6712\u001b[0m │\n",
       "│           ┆ \u001b[1;36m0\u001b[0m         ┆ \u001b[1;36m7\u001b[0m         ┆ \u001b[1;36m6\u001b[0m         ┆   ┆           ┆           ┆ \u001b[1;36m5\u001b[0m         ┆ \u001b[1;36m65\u001b[0m       │\n",
       "│           ┆ \u001b[1;92m23:00:00\u001b[0m  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "catalog.load('thb.primary_state_1h').collect().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and preprocess the data\n",
    "\n",
    "As we are only interested in the data when THEMIS is in the solar wind, for simplicity we will only keep the data when `X, SSE` and `X, GSE` is positive.\n",
    "\n",
    "- State data time resolution is 1 minute...\n",
    "\n",
    "- FGS data time resolution is 4 second..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thm_state(sat):\n",
    "    sat_pos_sse_files = f\"../data/{sat}_pos_sse.parquet\"\n",
    "    sat_pos_sse = pl.scan_parquet(sat_pos_sse_files).set_sorted(\"time\")\n",
    "    sat_pos_gse_files = f\"../data/{sat}_pos_gse.parquet\"\n",
    "    sat_pos_gse = pl.scan_parquet(sat_pos_gse_files).set_sorted(\"time\")\n",
    "    sat_state = sat_pos_sse.join(sat_pos_gse, on=\"time\", how=\"inner\")\n",
    "    return sat_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "def convert_thm_state_to_parquet(\n",
    "    probe: str, trange\n",
    "):\n",
    "    file_name = f\"./data/th{probe}_state.parquet\"\n",
    "    if os.path.exists(file_name):\n",
    "        return file_name\n",
    "\n",
    "    start = trange.start.to_string()\n",
    "    end = trange.end.to_string()\n",
    "\n",
    "    files = pyspedas.themis.state(\n",
    "        probe=probe,\n",
    "        trange=[start, end],\n",
    "        downloadonly=True,\n",
    "        no_update=True,\n",
    "    )\n",
    "\n",
    "    thm_pos_sse_Xs = []\n",
    "    thm_pos_gse_Xs = []\n",
    "    thm_state_times = []\n",
    "    for file in files:\n",
    "        thm_state = pycdfpp.load(file)\n",
    "        epoch_dt64 = thm_state[\n",
    "            f\"time\"\n",
    "        ].values  #  CATDESC: \"thm_state_time, UTC, in seconds since 01-Jan-1970 00:00:00\"\n",
    "        thm_pos_sse_Xs.append(thm_state[f\"th{probe}_pos_sse\"].values[:, 0])\n",
    "        thm_pos_gse_Xs.append(thm_state[f\"th{probe}_pos_gse\"].values[:, 0])\n",
    "        thm_state_times.append(epoch_dt64)\n",
    "\n",
    "    thm_pos_sse_X = np.concatenate(thm_pos_sse_Xs)\n",
    "    thm_pos_gse_X = np.concatenate(thm_pos_gse_Xs)\n",
    "    thm_state_time = np.concatenate(thm_state_times)\n",
    "\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"thm_state_time\": thm_state_time,\n",
    "            \"thm_pos_gse_X\": thm_pos_gse_X,\n",
    "            \"thm_pos_sse_X\": thm_pos_sse_X,\n",
    "        }\n",
    "    ).with_columns(\n",
    "        pl.from_epoch(pl.col(\"thm_state_time\"), time_unit=\"s\")\n",
    "    ).write_parquet(\n",
    "        file_name\n",
    "    )\n",
    "\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def convert_thm_fgm_to_parquet(probe, trange):\n",
    "    file_name = f\"./data/th{probe}_fgm.parquet\"\n",
    "    if os.path.exists(file_name):\n",
    "        return file_name\n",
    "\n",
    "    start = trange.start.to_string()\n",
    "    end = trange.end.to_string()\n",
    "    \n",
    "    files = pyspedas.themis.fgm(\n",
    "        probe=probe,\n",
    "        trange=[start, end],\n",
    "        downloadonly=True,\n",
    "        no_update=True,\n",
    "    )\n",
    "\n",
    "    thm_fgl_gses = []\n",
    "    thm_fgl_btotals = []\n",
    "    thm_fgl_times = []\n",
    "\n",
    "    for file in files:\n",
    "        cdf = pycdfpp.load(file)\n",
    "        thm_fgl_gses.append(cdf[f\"th{probe}_fgl_gse\"].values)\n",
    "        thm_fgl_btotals.append(cdf[f\"th{probe}_fgl_btotal\"].values)\n",
    "        thm_fgl_times.append(cdf[f\"th{probe}_fgl_time\"].values)\n",
    "\n",
    "    thm_fgl_gse = np.concatenate(thm_fgl_gses)\n",
    "    thm_fgl_btotal = np.concatenate(thm_fgl_btotals)\n",
    "    thm_fgl_time = np.concatenate(thm_fgl_times)\n",
    "\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"time\": thm_fgl_time,\n",
    "            \"BX\": thm_fgl_gse[:,0],\n",
    "            \"BY\": thm_fgl_gse[:,1],\n",
    "            \"BZ\": thm_fgl_gse[:,2],\n",
    "            \"B\": thm_fgl_btotal,\n",
    "        }\n",
    "    ).with_columns(\n",
    "        pl.from_epoch(pl.col(\"thm_fgl_time\"), time_unit=\"s\"),\n",
    "    ).write_parquet(   \n",
    "        file_name\n",
    "    )\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "df = (\n",
       "    sat_state_sw.upsample(\"time\", every=\"1m\")\n",
       "    .group_by_dynamic(\"time\", every=\"1d\")\n",
       "    .agg(pl.col(\"X, SSE\").null_count().alias(\"null_count\"))\n",
       "    .with_columns(\n",
       "        pl.when(pl.col(\"null_count\") > 720).then(0).otherwise(1).alias(\"availablity\")\n",
       "    )\n",
       ")\n",
       "\n",
       "properties = {\n",
       "    'width': 800,\n",
       "}\n",
       "\n",
       "chart1 = alt.Chart(df).mark_point().encode(\n",
       "    x='time',\n",
       "    y='null_count'\n",
       ").properties(**properties)\n",
       "\n",
       "chart2  = alt.Chart(df).mark_point().encode(\n",
       "    x='time',\n",
       "    y='availablity'\n",
       ").properties(**properties)\n",
       "\n",
       "(chart1 & chart2)\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.Markdown\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "df = (\n",
    "    sat_state_sw.upsample(\"time\", every=\"1m\")\n",
    "    .group_by_dynamic(\"time\", every=\"1d\")\n",
    "    .agg(pl.col(\"X, SSE\").null_count().alias(\"null_count\"))\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"null_count\") > 720).then(0).otherwise(1).alias(\"availablity\")\n",
    "    )\n",
    ")\n",
    "\n",
    "properties = {\n",
    "    'width': 800,\n",
    "}\n",
    "\n",
    "chart1 = alt.Chart(df).mark_point().encode(\n",
    "    x='time',\n",
    "    y='null_count'\n",
    ").properties(**properties)\n",
    "\n",
    "chart2  = alt.Chart(df).mark_point().encode(\n",
    "    x='time',\n",
    "    y='availablity'\n",
    ").properties(**properties)\n",
    "\n",
    "(chart1 & chart2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
