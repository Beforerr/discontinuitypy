{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State data pipeline\n",
    "\n",
    "Here we define state data to be the complementary data of the magnetic field data, useful for the analysis of the magnetic field data. It may include:\n",
    "\n",
    "- Plasma data\n",
    "- Satellite location data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "    probe: str = None,\n",
    "    coord: str = None,\n",
    "):\n",
    "    ...\n",
    "\n",
    "\n",
    "def load_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "    probe: str = None,\n",
    "    coord: str = None,\n",
    "):\n",
    "    \"\"\"Loading the raw dataset\n",
    "    \n",
    "    - Downloading data\n",
    "    - Reading data into a proper data structure, like dataframe.\n",
    "        - Parsing original data (dealing with delimiters, missing values, etc.)\n",
    "    \"\"\"\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state_data(\n",
    "    raw_data: Any = None,\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = None,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Parsing and typing data (like from string to datetime for time columns)\n",
    "    - Structuring the data (like pivoting, unpivoting, etc.)\n",
    "    - Changing storing format (like from `csv` to `parquet`)\n",
    "    - Dropping null columns\n",
    "    - Resampling data to a given time resolution (better to do in the next stage)\n",
    "    - ... other 'transformations' commonly performed at this stage.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_data(df: pl.DataFrame, columns=None,) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Corresponding to primary data layer, where source data models are transformed into domain data models\n",
    "\n",
    "    - Transforming data to RTN (Radial-Tangential-Normal) coordinate system\n",
    "    - Discarding unnecessary columns\n",
    "    - Smoothing data\n",
    "    - Resampling data to a given time resolution\n",
    "    - Partitioning data, for the sake of memory\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_data_pipeline(\n",
    "    sat_id,\n",
    "    ts: str = '1h',  # time resolution\n",
    ") -> Pipeline:\n",
    "    \n",
    "    node_load_data = node(\n",
    "        load_state_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=\"raw_state\",\n",
    "        name=f\"download_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    node_preprocess_data = node(\n",
    "        preprocess_state_data,\n",
    "        inputs=dict(\n",
    "            raw_data=\"raw_state\",\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"inter_state_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    node_process_data = node(\n",
    "        process_state_data,\n",
    "        inputs=f\"inter_state_{ts}\",\n",
    "        outputs=f\"primary_state_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    nodes = [\n",
    "        node_load_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "    ]\n",
    "\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
