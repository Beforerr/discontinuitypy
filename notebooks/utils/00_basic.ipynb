{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Utils\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils/basic\n",
    "# | export\n",
    "from typing import overload\n",
    "from typing import Union, Collection, Callable, Tuple\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "from xarray_einstats import linalg\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from xarray import DataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Polars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_tranges(time: pl.Series, tranges: Tuple[list, list]):\n",
    "    \"\"\"\n",
    "    - Filter data by time ranges, return the indices of the time that are in the time ranges (left inclusive, right exclusive)\n",
    "    \"\"\"\n",
    "\n",
    "    starts = tranges[0]\n",
    "    ends = tranges[1]\n",
    "\n",
    "    start_indices = time.search_sorted(starts)\n",
    "    end_indices = time.search_sorted(ends)\n",
    "\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.arange(start_index, end_index)\n",
    "            for start_index, end_index in zip(start_indices, end_indices)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_tranges_df(\n",
    "    df: pl.DataFrame, tranges: Tuple[list, list], time_col: str = \"time\"\n",
    "):\n",
    "    \"\"\"\n",
    "    - Filter data by time ranges\n",
    "    \"\"\"\n",
    "\n",
    "    time = df[time_col]\n",
    "    filtered_indices = filter_tranges(time, tranges)\n",
    "    return df[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def plot(self: pl.DataFrame, *args, **kwargs):\n",
    "    return self.to_pandas().plot(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _expand_selectors(items: Any, *more_items: Any) -> list[Any]:\n",
    "    \"\"\"\n",
    "    See `_expand_selectors` in `polars`.\n",
    "    \"\"\"\n",
    "    expanded: list[Any] = []\n",
    "    for item in (\n",
    "        *(\n",
    "            items\n",
    "            if isinstance(items, Collection) and not isinstance(items, str)\n",
    "            else [items]\n",
    "        ),\n",
    "        *more_items,\n",
    "    ):\n",
    "        expanded.append(item)\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition the dataset by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def partition_data_by_ts(df: pl.DataFrame, ts: timedelta) -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"Partition the dataset by time\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame.\n",
    "        ts: Time interval.\n",
    "\n",
    "    Returns:\n",
    "        Partitioned DataFrame.\n",
    "    \"\"\"\n",
    "    return df.with_columns(\n",
    "        key=pl.col(\"time\").dt.truncate(ts).cast(pl.Utf8)\n",
    "    ).partition_by(\"key\", include_key=False, as_dict=True)\n",
    "\n",
    "\n",
    "def partition_data_by_year(df: pl.DataFrame) -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"Partition the dataset by year\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Partitioned DataFrame.\n",
    "    \"\"\"\n",
    "    return df.with_columns(year=pl.col(\"time\").dt.year().cast(pl.Utf8)).partition_by(\n",
    "        \"year\", include_key=False, as_dict=True\n",
    "    )\n",
    "\n",
    "\n",
    "def partition_data_by_year_month(df: pl.DataFrame) -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"Partition the dataset by year\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Partitioned DataFrame.\n",
    "    \"\"\"\n",
    "    return df.with_columns(\n",
    "        year_month=pl.col(\"time\").dt.year().cast(pl.Utf8)\n",
    "        + \"_\"\n",
    "        + pl.col(\"time\").dt.month().cast(pl.Utf8).str.zfill(2),\n",
    "    ).partition_by(\"year_month\", include_key=False, as_dict=True)\n",
    "\n",
    "\n",
    "def partition_data_by_time(\n",
    "    df: pl.LazyFrame | pl.DataFrame, method\n",
    ") -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"Partition the dataset by time\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame.\n",
    "        method: The method to partition the data.\n",
    "\n",
    "    Returns:\n",
    "        Partitioned DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "\n",
    "    if method == \"year\":\n",
    "        return partition_data_by_year(df)\n",
    "    elif method == \"year_month\":\n",
    "        return partition_data_by_year_month(df)\n",
    "    else:\n",
    "        ts = pd.Timedelta(method)\n",
    "        return partition_data_by_ts(df, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "DF_TYPE = Union[pl.DataFrame, pl.LazyFrame, pd.DataFrame]\n",
    "\n",
    "\n",
    "def concat_df(dfs: list[DF_TYPE]) -> DF_TYPE:\n",
    "    \"\"\"Concatenate a list of DataFrames into one DataFrame.\"\"\"\n",
    "\n",
    "    match type(dfs[0]):\n",
    "        case pl.DataFrame | pl.LazyFrame:\n",
    "            concat_func = pl.concat\n",
    "        case pandas.DataFrame:\n",
    "            concat_func = pandas.concat\n",
    "        case _:\n",
    "            raise ValueError(f\"Unsupported DataFrame type: {type(dfs[0])}\")\n",
    "\n",
    "    return concat_func(dfs)\n",
    "\n",
    "\n",
    "def concat_partitions(partitioned_input: Dict[str, Callable]):\n",
    "    \"\"\"Concatenate input partitions into one DataFrame.\n",
    "\n",
    "    Args:\n",
    "        partitioned_input: A dictionary with partition ids as keys and load functions as values.\n",
    "    \"\"\"\n",
    "    partitions_data = [\n",
    "        partition_load_func() for partition_load_func in partitioned_input.values()\n",
    "    ]  # load the actual partition data\n",
    "\n",
    "    result = concat_df(partitions_data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def format_timedelta(time):\n",
    "    \"\"\"Format timedelta to `timedelta`\"\"\"\n",
    "    if isinstance(time, timedelta):\n",
    "        return time\n",
    "    elif isinstance(time, str):\n",
    "        return pd.Timedelta(time)\n",
    "    elif isinstance(time, int):\n",
    "        return pd.Timedelta(seconds=time)\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported type: {type(time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@overload\n",
    "def resample(\n",
    "    df: pl.DataFrame,\n",
    "    every: timedelta,\n",
    "    period: timedelta = None,\n",
    "    offset: timedelta = None,\n",
    "    shift: timedelta = None,\n",
    "    time_column=\"time\",\n",
    ") -> pl.DataFrame: ...\n",
    "\n",
    "\n",
    "@overload\n",
    "def resample(\n",
    "    df: pl.LazyFrame,\n",
    "    every: timedelta,\n",
    "    period: timedelta = None,\n",
    "    offset: timedelta = None,\n",
    "    shift: timedelta = None,\n",
    "    time_column=\"time\",\n",
    ") -> pl.LazyFrame: ...\n",
    "\n",
    "\n",
    "def resample(\n",
    "    df: pl.LazyFrame | pl.DataFrame,\n",
    "    every: timedelta,\n",
    "    period: timedelta = None,\n",
    "    offset: timedelta = None,\n",
    "    shift: timedelta = None,\n",
    "    time_column=\"time\",\n",
    "):\n",
    "    \"\"\"Resample the DataFrame\"\"\"\n",
    "    if period is None:\n",
    "        period = every\n",
    "    if shift is None:\n",
    "        shift = period / 2\n",
    "    return (\n",
    "        df.sort(time_column)\n",
    "        .group_by_dynamic(time_column, every=every, period=period, offset=offset)\n",
    "        .agg(cs.numeric().mean())\n",
    "        .with_columns((pl.col(time_column) + shift))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def df2ts(\n",
    "    df: Union[pandas.DataFrame, pl.DataFrame, pl.LazyFrame],\n",
    "    cols=None,\n",
    "    time_col=\"time\",\n",
    "    attrs=None,\n",
    "    name=None,\n",
    "):\n",
    "    \"\"\"Convert DataFrame to TimeSeries\"\"\"\n",
    "\n",
    "    if cols is None:\n",
    "        if isinstance(df, (pl.DataFrame, pl.LazyFrame)):\n",
    "            cols = df.columns\n",
    "            cols.remove(time_col)\n",
    "        else:\n",
    "            cols = df.columns.tolist()\n",
    "\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "\n",
    "    # Prepare data\n",
    "    data = df[cols].to_numpy()\n",
    "\n",
    "    # Prepare coordinates\n",
    "    time = df.index if isinstance(df, pandas.DataFrame) else df[time_col]\n",
    "    if isinstance(cols, str) and len(data.shape) > 1:\n",
    "        element_len = data.shape[1]\n",
    "        v_dim = [cols + str(i) for i in range(element_len)]\n",
    "    else:\n",
    "        v_dim = cols\n",
    "\n",
    "    # Create the DataArray\n",
    "    coords = {\"time\": time, \"v_dim\": v_dim}\n",
    "\n",
    "    return xr.DataArray(data, coords=coords, attrs=attrs, name=name)\n",
    "\n",
    "\n",
    "def calc_vec_mag(vec) -> DataArray:\n",
    "    return linalg.norm(vec, dims=\"v_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def check_fgm(vec: xr.DataArray):\n",
    "    # check if time is monotonic increasing\n",
    "    logger.info(\"Check if time is monotonic increasing\")\n",
    "    assert vec.time.to_series().is_monotonic_increasing\n",
    "    # check available time difference\n",
    "    logger.info(\n",
    "        f\"Available time delta: {vec.time.diff(dim='time').to_series().unique()}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
