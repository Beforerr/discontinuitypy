{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Datasets\"\n",
    "description: This notebook contains the code to deal with all candidates and individual candidate.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import xarray as xr\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Kerdo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline\n",
    "from ids_finder.utils.basic import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "catalog = load_catalog('../')\n",
    "catalog.list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining magnetic field data and state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "\n",
    "from ids_finder.utils.basic import df2ts, pl_norm\n",
    "import xarray as xr\n",
    "from xarray_einstats import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def combine(candidates: pl.LazyFrame, states_data: pl.LazyFrame):\n",
    "    vec_cols = [\"v_x\", \"v_y\", \"v_z\"]  # plasma velocity vector in any coordinate system\n",
    "    b_vecL_cols = [\"Vl_x\", \"Vl_y\", \"Vl_z\"]  # major eigenvector in any coordinate system\n",
    "    if not set(vec_cols).issubset(states_data.columns):\n",
    "        raise ValueError(f\"Missing columns {vec_cols}\")\n",
    "    if not set(b_vecL_cols).issubset(candidates.columns):\n",
    "        raise ValueError(f\"Missing columns {b_vecL_cols}\")\n",
    "\n",
    "    return candidates.sort(\"time\").join_asof(states_data.sort(\"time\"), on=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating additional features for the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import astropy.units as u\n",
    "from astropy.constants import mu0\n",
    "from plasmapy.formulary.lengths import inertial_length\n",
    "from plasmapy.formulary.speeds import Alfven_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def vector_project(v1,v2, dim=\"v_dim\"):\n",
    "    return xr.dot(v1 , v2, dims=dim) / linalg.norm(v2, dims=dim)\n",
    "\n",
    "def vector_project_pl(df: pl.DataFrame, v1_cols, v2_cols, name=None):\n",
    "    \n",
    "    v1 = df2ts(df, v1_cols).assign_coords(v_dim=[\"r\",\"t\",\"n\"])\n",
    "    v2 = df2ts(df, v2_cols).assign_coords(v_dim=[\"r\",\"t\",\"n\"]) \n",
    "    result = vector_project(v1, v2, dim=\"v_dim\")\n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.Series(result.data).alias(name or \"v_proj\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_inertial_length(ldf: pl.LazyFrame):\n",
    "    df = ldf.collect()\n",
    "    \n",
    "    density = df['plasma_density'].to_numpy() * u.cm**(-3)\n",
    "    result = inertial_length(density, 'H+').to(u.km)\n",
    "    \n",
    "    return df.with_columns(\n",
    "        ion_inertial_length = pl.Series(result.value)\n",
    "    ).lazy()\n",
    "    \n",
    "def compute_Alfven_speed(ldf: pl.LazyFrame):\n",
    "    df = ldf.collect()\n",
    "    \n",
    "    B = df['B'] if 'B' in df.columns else df['b_mag'] # backwards compatiblity\n",
    "    density = df['plasma_density'].to_numpy() * u.cm**(-3)\n",
    "    result = Alfven_speed(B.to_numpy() * u.nT, density=density, ion='p+').to(u.km/u.s)\n",
    "    \n",
    "    return df.with_columns(\n",
    "        Alfven_speed = pl.Series(result.value)\n",
    "    ).lazy()\n",
    "\n",
    "\n",
    "\n",
    "def unitize(df: pl.LazyFrame):\n",
    "    \"\"\"unitize the columns in the dataframe with\n",
    "    \"\"\"\n",
    "    \n",
    "    j_factor = ((u.nT/u.s) * (1 / mu0 / (u.km/u.s) )).to(u.nA/u.m**2)\n",
    "\n",
    "    return df.with_columns(\n",
    "        j0 = pl.col('j0') * j_factor.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def calc_combined_features(df: pl.LazyFrame):\n",
    "    vec_cols = [\"v_x\", \"v_y\", \"v_z\"]  # plasma velocity vector in any coordinate system\n",
    "    b_vecL_cols = [\"Vl_x\", \"Vl_y\", \"Vl_z\"]  # major eigenvector in any coordinate system\n",
    "\n",
    "    result = (\n",
    "        df.with_columns(\n",
    "            duration=pl.col(\"d_tstop\") - pl.col(\"d_tstart\"),\n",
    "        )\n",
    "        .pipe(vector_project_pl, vec_cols, b_vecL_cols, name=\"v_l\")\n",
    "        .with_columns(v_mn=(pl.col(\"plasma_speed\") ** 2 - pl.col(\"v_l\") ** 2).sqrt())\n",
    "        .with_columns(\n",
    "            L_mn=pl.col(\"v_mn\") * pl.col(\"duration\").dt.nanoseconds() / 1e9,\n",
    "            j0=pl.col(\"d_star\") / pl.col(\"v_mn\"),\n",
    "        )\n",
    "        .pipe(compute_inertial_length)\n",
    "        .pipe(compute_Alfven_speed)\n",
    "        .pipe(unitize)\n",
    "        .with_columns(\n",
    "            L_mn_norm=pl.col(\"L_mn\") / pl.col(\"ion_inertial_length\"),\n",
    "            j0_norm=pl.col(\"d_star\") / pl.col(\"Alfven_speed\"),\n",
    "        )\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def combine_features(candidates: pl.LazyFrame, states_data: pl.LazyFrame):\n",
    "    df = combine(candidates, states_data)\n",
    "    updated_df = calc_combined_features(df)\n",
    "\n",
    "    return updated_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel\n",
    "from kedro.io import DataCatalog\n",
    "from ids_finder.utils.basic import concat_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IDsDataset(BaseModel):\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        extra = \"allow\"\n",
    "\n",
    "    sat_id: str\n",
    "    tau: timedelta\n",
    "    ts: timedelta = 1\n",
    "    catalog: DataCatalog\n",
    "    \n",
    "    candidates: pl.DataFrame | None = None\n",
    "    data: pl.LazyFrame | None = None    # data is large, so we use `pl.LazyFrame` to save memory\n",
    "\n",
    "    or_df: pl.DataFrame | None = None  # occurence rate\n",
    "    or_df_normalized: pl.DataFrame | None = None # normalized occurence rate\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "\n",
    "        if self.candidates is None:\n",
    "            self.load_candidates()\n",
    "        if self.data is None:\n",
    "            self.load_data()\n",
    "\n",
    "    def load_candidates(self):\n",
    "        candidates_format = f\"candidates.{self.sat_id}_tau_{self.tau.seconds}s\"\n",
    "\n",
    "        self.candidates = self.catalog.load(candidates_format).fill_nan(None).with_columns(\n",
    "            cs.float().cast(pl.Float64)\n",
    "        ).collect()\n",
    "\n",
    "    def load_data(self):\n",
    "        data_format = f\"{self.sat_id}.primary_mag_{self.ts.seconds}s\"\n",
    "        self.data = concat_partitions(self.catalog.load(data_format))\n",
    "    \n",
    "    def plot_candidates(self, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ids_finder.utils.basic import calc_vec_mag\n",
    "from pyspedas.cotrans.minvar_matrix_make import minvar_matrix_make\n",
    "from pyspedas import tvector_rotate\n",
    "from pytplot import timebar, store_data, tplot, split_vec, join_vec, tplot_options, options, highlight, degap\n",
    "import pytplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting\n",
    "def time_stamp(ts):\n",
    "    \"Return POSIX timestamp as float.\"\n",
    "    return pd.Timestamp(ts, tz=\"UTC\").timestamp()\n",
    "\n",
    "def plot_basic(\n",
    "    data: xr.DataArray, \n",
    "    tstart: pd.Timestamp, \n",
    "    tstop: pd.Timestamp,\n",
    "    tau: timedelta, \n",
    "    mva_tstart=None, mva_tstop=None, neighbor: int = 1\n",
    "):\n",
    "    if mva_tstart is None:\n",
    "        mva_tstart = tstart\n",
    "    if mva_tstop is None:\n",
    "        mva_tstop = tstop\n",
    "\n",
    "    mva_b = data.sel(time=slice(mva_tstart, mva_tstop))\n",
    "    store_data(\"fgm\", data={\"x\": mva_b.time, \"y\": mva_b})\n",
    "    minvar_matrix_make(\"fgm\")  # get the MVA matrix\n",
    "\n",
    "    temp_tstart = tstart - neighbor * tau\n",
    "    temp_tstop = tstop + neighbor * tau\n",
    "\n",
    "    temp_b = data.sel(time=slice(temp_tstart, temp_tstop))\n",
    "    store_data(\"fgm\", data={\"x\": temp_b.time, \"y\": temp_b})\n",
    "    temp_btotal = calc_vec_mag(temp_b)\n",
    "    store_data(\"fgm_btotal\", data={\"x\": temp_btotal.time, \"y\": temp_btotal})\n",
    "\n",
    "    tvector_rotate(\"fgm_mva_mat\", \"fgm\")\n",
    "    split_vec(\"fgm_rot\")\n",
    "    pytplot.data_quants[\"fgm_btotal\"][\"time\"] = pytplot.data_quants[\"fgm_rot\"][\n",
    "        \"time\"\n",
    "    ]  # NOTE: whenever using `get_data`, we may lose precision in the time values. This is a workaround.\n",
    "    join_vec(\n",
    "        [\n",
    "            \"fgm_rot_x\",\n",
    "            \"fgm_rot_y\",\n",
    "            \"fgm_rot_z\",\n",
    "            \"fgm_btotal\",\n",
    "        ],\n",
    "        new_tvar=\"fgm_all\",\n",
    "    )\n",
    "\n",
    "    options(\"fgm\", \"legend_names\", [r\"$B_x$\", r\"$B_y$\", r\"$B_z$\"])\n",
    "    options(\"fgm_all\", \"legend_names\", [r\"$B_l$\", r\"$B_m$\", r\"$B_n$\", r\"$B_{total}$\"])\n",
    "    options(\"fgm_all\", \"ysubtitle\", \"[nT LMN]\")\n",
    "    tstart_ts = time_stamp(tstart)\n",
    "    tstop_ts = time_stamp(tstop)\n",
    "    # .replace(tzinfo=ZoneInfo('UTC')).timestamp()\n",
    "    highlight([\"fgm\", \"fgm_all\"], [tstart_ts, tstop_ts])\n",
    "    \n",
    "    degap(\"fgm\")\n",
    "    degap(\"fgm_all\")\n",
    "\n",
    "def format_candidate_title(candidate: pandas.Series):\n",
    "    format_float = lambda x: rf\"$\\bf {x:.2f} $\" if isinstance(x, (float, int)) else rf\"$\\bf {x} $\"\n",
    "\n",
    "    base_line = rf'$\\bf {candidate.get(\"type\", \"N/A\")} $ candidate (time: {candidate.get(\"time\", \"N/A\")}) with index '\n",
    "    index_line = rf'i1: {format_float(candidate.get(\"index_std\", \"N/A\"))}, i2: {format_float(candidate.get(\"index_fluctuation\", \"N/A\"))}, i3: {format_float(candidate.get(\"index_diff\", \"N/A\"))}'\n",
    "    info_line = rf'$B_n/B$: {format_float(candidate.get(\"BnOverB\", \"N/A\"))}, $dB/B$: {format_float(candidate.get(\"dBOverB\", \"N/A\"))}, $(dB/B)_{{max}}$: {format_float(candidate.get(\"dBOverB_max\", \"N/A\"))},  $Q_{{mva}}$: {format_float(candidate.get(\"Q_mva\", \"N/A\"))}'\n",
    "    title = rf\"\"\"{base_line}\n",
    "    {index_line}\n",
    "    {info_line}\"\"\"\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_candidate_xr(candidate: pandas.Series, sat_fgm: xr.DataArray, tau: timedelta):\n",
    "    if pd.notnull(candidate.get(\"d_tstart\")) and pd.notnull(candidate.get(\"d_tstop\")):\n",
    "        plot_basic(\n",
    "            sat_fgm,\n",
    "            candidate[\"tstart\"],\n",
    "            candidate[\"tstop\"],\n",
    "            tau,\n",
    "            candidate[\"d_tstart\"],\n",
    "            candidate[\"d_tstop\"],\n",
    "        )\n",
    "    else:\n",
    "        plot_basic(sat_fgm, candidate[\"tstart\"], candidate[\"tstop\"], tau)\n",
    "\n",
    "    tplot_options(\"title\", format_candidate_title(candidate))\n",
    "\n",
    "    if \"d_time\" in candidate.keys():\n",
    "        d_time_ts = time_stamp(candidate[\"d_time\"])\n",
    "        timebar(d_time_ts, color=\"red\")\n",
    "    if \"d_tstart\" in candidate.keys() and not pd.isnull(candidate[\"d_tstart\"]):\n",
    "        d_start_ts = time_stamp(candidate[\"d_tstart\"])\n",
    "        timebar(d_start_ts)\n",
    "    if \"d_tstop\" in candidate.keys() and not pd.isnull(candidate[\"d_tstop\"]):\n",
    "        d_stop_ts = time_stamp(candidate[\"d_tstop\"])\n",
    "        timebar(d_stop_ts)\n",
    "\n",
    "    tplot(\"fgm_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_candidates(\n",
    "    candidates: pandas.DataFrame, candidate_type=None, num=4, plot_func=plot_candidate\n",
    "):\n",
    "    \"\"\"Plot a set of candidates.\n",
    "\n",
    "    Parameters:\n",
    "    - candidates (pd.DataFrame): DataFrame containing the candidates.\n",
    "    - candidate_type (str, optional): Filter candidates based on a specific type.\n",
    "    - num (int): Number of candidates to plot, selected randomly.\n",
    "    - plot_func (callable): Function used to plot an individual candidate.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter by candidate_type if provided\n",
    "    \n",
    "    candidates = get_candidates(candidates, candidate_type, num)\n",
    "\n",
    "    # Plot each candidate using the provided plotting function\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        plot_func(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CandidateID:\n",
    "    def __init__(self, time, df: pl.DataFrame) -> None:\n",
    "        self.time = pd.Timestamp(time)\n",
    "        self.data = df.row(\n",
    "            by_predicate=(pl.col(\"time\") == self.time), \n",
    "            named=True\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # return self.data.__repr__()\n",
    "        pprint(self.data)\n",
    "        return ''\n",
    "    \n",
    "    def plot(self, sat_fgm, tau):\n",
    "        plot_candidate_xr(self.data, sat_fgm, tau)\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_candidates_1s: pl.DataFrame = catalog.load('candidates.sta_1s')\n",
    "jno_candidates_1s = catalog.load('candidates.jno_1s')\n",
    "\n",
    "sta_mag : pl.LazyFrame = catalog.load('sta.inter_mag_rtn_1s')\n",
    "jno_mag : pl.LazyFrame = catalog.load('sta.inter_mag_rtn_1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ids_finder.utils.basic import df2ts, pmap\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_candidate(candidate, mag_data: pl.LazyFrame, b_cols = ['BX', 'BY', 'BZ']):\n",
    "    temp_tstart = candidate[\"tstart\"]\n",
    "    tmep_tstop = candidate[\"tstop\"]\n",
    "    tau = tmep_tstop - temp_tstart\n",
    "\n",
    "    temp_mag_data = (\n",
    "        mag_data.filter(pl.col(\"time\").is_between(temp_tstart - tau, tmep_tstop + tau))\n",
    "        .with_columns(pl.col(\"time\").dt.cast_time_unit(\"ns\"))\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    sat_fgm = df2ts(temp_mag_data, b_cols)\n",
    "    plot_candidate_xr(candidate, sat_fgm, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "# list(sta_candidates_1s.sample(n).iter_rows(named=True) | pmap(plot_candidate, mag_data=sta_mag))\n",
    "\n",
    "candidates = jno_candidates_1s.sample(n)\n",
    "list(candidates.iter_rows(named=True) | pmap(plot_candidate, mag_data=jno_mag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_candidate_pipeline(\n",
    "    sat_id, \n",
    "    tau: str = \"60s\",\n",
    "    ts_state: str = \"1h\",\n",
    "    **kwargs) -> Pipeline:\n",
    "\n",
    "    node_combine_features = node(\n",
    "        combine_features,\n",
    "        inputs=[\n",
    "            f\"{sat_id}.feature_tau_{tau}\",\n",
    "            f\"{sat_id}.primary_state_{ts_state}\",\n",
    "        ],\n",
    "        outputs=f\"candidates.{sat_id}_tau_{tau}\",\n",
    "    )\n",
    "\n",
    "    nodes = [node_combine_features]\n",
    "    return pipeline(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
