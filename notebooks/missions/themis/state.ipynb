{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: THEMIS State data pipeline\n",
    "---\n",
    "\n",
    "We use low resolution [OMNI data](https://omniweb.gsfc.nasa.gov/ow.html) for plasma state data, see [details](https://spdf.gsfc.nasa.gov/pub/data/omni/low_res_omni/omni2.text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Data gaps were filled with dummy numbers for the missing hours or entire\n",
    "  days to make all files of equal length.  The character '9' is used to\n",
    "  fill all fields for missing data according to their format, e.g.\n",
    "  ' 9999.9' for a field with the FORTRAN format F7.1. Note that format F7.1\n",
    "  below really means (1X,F6.1),etc.\n",
    "\n",
    "```\n",
    "The flow OMNI \"phi\" angle is opposite GSE \"phi\" angle, threrfore, Flow-vector cartesian components in GSE coordinates may be derived from the given speed and angles as\n",
    "\n",
    "Vx = - V * cos(theta) * cos(phi)\n",
    "Vy = + V * cos(theta) * sin(phi)\n",
    "Vz = + V * sin(theta)\n",
    "and vise versa: two angles may be derived from the given speed and Vx,Vy,Vz comp. as  \n",
    "          a_theta=vz/V\n",
    "          theta=(180.*asin(a_theta))/!PI\n",
    "         a_phi=Vy/(-Vx)\n",
    "        phi=(180.*atan(a_phi))/!PI\n",
    "```\n",
    "\n",
    "```\n",
    "   (*)   Quasi-GSE for the flow longitude angle means the angle increases from zero\n",
    "         to positive values as the flow changes from being aligned along the -X(GSE)\n",
    "         axis towards the +Y(GSE) axis.  The flow longitude angle is positive for \n",
    "         flow from west of the sun, towards +Y(GSE).\n",
    "         The flow latitude angle is positive for flow from south of the sun, \n",
    "         towards +Z(GSE)\n",
    "``````                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "import pandas\n",
    "\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/themis/state\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from ids_finder.utils.basic import cdf2pl, pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def download_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "    probe: str = None,\n",
    "    coord: str = None,\n",
    "):\n",
    "    import pyspedas\n",
    "\n",
    "    trange = [start, end]\n",
    "    files = pyspedas.omni.data(trange=trange, datatype=\"hour\", downloadonly=True)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    ts: str = None,  # time resolution\n",
    "    vars: dict = None,\n",
    "):\n",
    "    files = download_state_data(start, end, ts, vars)\n",
    "    df: pl.LazyFrame = pl.concat(files | pmap(cdf2pl, var_names=list(vars)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_data(\n",
    "    raw_data: pl.LazyFrame,\n",
    "    vars: dict,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Extracting variables from `CDF` files, and convert them to DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    columns_name_mapping = {key: value[\"COLNAME\"] for key, value in vars.items()}\n",
    "\n",
    "    return raw_data.rename(columns_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we have additional data file that indicate if `THEMIS` is in solar wind or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_sw_state_data(\n",
    "    raw_data: pandas.DataFrame,\n",
    ") -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    - Applying naming conventions for columns\n",
    "    - Parsing and typing data (like from string to datetime for time columns)\n",
    "    \"\"\"\n",
    "\n",
    "    return pl.from_dataframe(raw_data).with_columns(\n",
    "        # Note: For `polars`, please either specify both hour and minute, or neither.\n",
    "        pl.concat_str(pl.col(\"start\"), pl.lit(\" 00\")).str.to_datetime(\n",
    "            format=\"%Y %j %H %M\"\n",
    "        ),\n",
    "        pl.concat_str(pl.col(\"end\"), pl.lit(\" 00\")).str.to_datetime(\n",
    "            format=\"%Y %j %H %M\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def flow2gse(df: pl.LazyFrame) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    - Transforming solar wind data from `Quasi-GSE` coordinate to GSE coordinate system\n",
    "    \"\"\"\n",
    "    plasma_speed = pl.col(\"plasma_speed\")\n",
    "    sw_theta = pl.col(\"sw_vel_theta\")\n",
    "    sw_phi = pl.col(\"sw_vel_phi\")\n",
    "\n",
    "    return df.with_columns(\n",
    "        sw_vel_gse_x=-plasma_speed * sw_theta.cos() * sw_phi.cos(),\n",
    "        sw_vel_gse_y=+plasma_speed * sw_theta.cos() * sw_phi.sin(),\n",
    "        sw_vel_gse_z=+plasma_speed * sw_theta.sin(),\n",
    "    ).drop([\"sw_theta\", \"sw_phi\"])\n",
    "\n",
    "\n",
    "def filter_tranges(time: pl.Series, tranges: tuple[list, list]):\n",
    "    \"\"\"\n",
    "    - Filter data by time ranges, return the indices of the time that are in the time ranges\n",
    "    \"\"\"\n",
    "\n",
    "    starts = tranges[0]\n",
    "    ends = tranges[1]\n",
    "\n",
    "    start_indices = time.search_sorted(starts)\n",
    "    end_indices = time.search_sorted(ends)\n",
    "\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.arange(start_index, end_index + 1)\n",
    "            for start_index, end_index in zip(start_indices, end_indices)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def add_state(l_df: pl.LazyFrame, l_state: pl.LazyFrame):\n",
    "    state = l_state.collect()\n",
    "    df = l_df.collect()\n",
    "\n",
    "    start = state.get_column(\"start\")\n",
    "    end = state.get_column(\"end\")\n",
    "\n",
    "    time = df.get_column(\"time\")\n",
    "\n",
    "    indices = filter_tranges(time, (start, end))\n",
    "\n",
    "    return (\n",
    "        df.with_row_count()\n",
    "        .with_columns(\n",
    "            state=pl.when(pl.col(\"row_nr\").is_in(indices)).then(1).otherwise(0)\n",
    "        )\n",
    "        .drop(\"row_nr\")\n",
    "    )\n",
    "\n",
    "\n",
    "def process_data(df: pl.LazyFrame, state: pl.LazyFrame = None) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    - Transforming data to GSE coordinate system\n",
    "    - Combine state data with additional plasma state data\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        df.pipe(flow2gse)\n",
    "        .pipe(add_state, state)\n",
    "        .rename(\n",
    "            {\n",
    "                \"sw_vel_gse_x\": \"v_x\",\n",
    "                \"sw_vel_gse_y\": \"v_y\",\n",
    "                \"sw_vel_gse_z\": \"v_z\",\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_pipeline(\n",
    "    sat_id,\n",
    "    ts: str = \"1h\",  # time resolution\n",
    ") -> Pipeline:\n",
    "    node_load_data = node(\n",
    "        load_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "            vars=\"params:omni_vars\",\n",
    "        ),\n",
    "        outputs=\"raw_state\",\n",
    "        name=f\"load_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_data,\n",
    "        inputs=dict(\n",
    "            raw_data=\"raw_state\",\n",
    "            vars=\"params:omni_vars\",\n",
    "        ),\n",
    "        outputs=f\"inter_state_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_sw_state = node(\n",
    "        preprocess_sw_state_data,\n",
    "        inputs=\"raw_state_sw\",\n",
    "        outputs=\"inter_state_sw\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_solar_wind_state_data\",\n",
    "    )\n",
    "\n",
    "    node_process_data = node(\n",
    "        process_data,\n",
    "        inputs=[f\"inter_state_{ts}\", \"inter_state_sw\"],\n",
    "        outputs=f\"primary_state_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    nodes = [\n",
    "        node_load_data,\n",
    "        node_preprocess_data,\n",
    "        node_preprocess_sw_state,\n",
    "        node_process_data,\n",
    "    ]\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:omni_vars\": \"params:omni_vars\",\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# catalog.load(\"thb.primary_state_1h\").collect().describe()\n",
    "# catalog.load('thb.feature_tau_60s').collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_planet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
