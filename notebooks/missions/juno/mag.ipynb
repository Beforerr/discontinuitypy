{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: JUNO Magnetic field data pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import timedelta\n",
    "import polars as pl\n",
    "\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/juno/mag\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pooch\n",
    "from pooch import Unzip\n",
    "from ids_finder.utils.basic import load_lbl, concat_partitions\n",
    "from pipe import select, filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "time_resolutions = [\"1sec\", \"1min\"]\n",
    "\n",
    "\n",
    "def download_mag_data(\n",
    "    start=None,\n",
    "    end=None,\n",
    "    ts: str = \"1sec\",  # time resolution\n",
    ") -> list[str]:\n",
    "    base_url = \"https://pds-ppi.igpp.ucla.edu/ditdos/download?id=pds://PPI/JNO-SS-3-FGM-CAL-V1.0/DATA/CRUISE/SE\"\n",
    "    files = pooch.retrieve(\n",
    "        url=f\"{base_url}/{ts.upper()}\",\n",
    "        known_hash=None,\n",
    "        path=\"../data/01_raw/\",\n",
    "        processor=Unzip(extract_dir=f\"jno_ss_se_{ts}\"),\n",
    "    )\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_mag_data(\n",
    "    start: str | None = None,\n",
    "    end: str | None = None,\n",
    "    ts: str = \"1sec\",  # time resolution\n",
    ") -> pl.DataFrame:\n",
    "    files = download_mag_data(start, end, ts)\n",
    "\n",
    "    data = pl.concat(\n",
    "        files\n",
    "        | filter(lambda x: x.endswith(\".lbl\"))\n",
    "        | select(load_lbl)\n",
    "        | select(pl.from_dataframe)\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Convert all files from `lbl` format to `parquet` format for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.basic import concat_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_mag_data(raw_data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Parsing and typing data\n",
    "    - Changing storing format (from `lbl` to `parquet`)\n",
    "    - Dropping useless columns\n",
    "    \"\"\"\n",
    "\n",
    "    df_pl = (\n",
    "        raw_data\n",
    "        .lazy()\n",
    "        .with_columns(time=pl.col(\"SAMPLE UTC\").str.to_datetime(\"%Y %j %H %M %S %f\"))\n",
    "        .drop([\"SAMPLE UTC\", \"DECIMAL DAY\", \"INSTRUMENT RANGE\"])\n",
    "        .sort(\"time\")\n",
    "        .collect()\n",
    "    )\n",
    "    return df_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from ids_finder.utils.basic import partition_data_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_mag_data(\n",
    "    raw_data: pl.DataFrame,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = None,\n",
    ") -> pl.DataFrame | Dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Partitioning data, for the sake of memory\n",
    "    \"\"\"\n",
    "    return partition_data_by_year(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_pipeline(\n",
    "    sat_id,\n",
    "    ts: str = \"1s\",  # time resolution,\n",
    "    tau: str = \"60s\",  # time window\n",
    "    **kwargs,\n",
    ") -> Pipeline:\n",
    "\n",
    "    node_download_data = node(\n",
    "        load_mag_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"raw_mag_files_{ts}\",\n",
    "        name=f\"download_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_mag_data,\n",
    "        inputs=dict(\n",
    "            raw_data=f\"raw_mag_{ts}\",\n",
    "        ),\n",
    "        outputs=f\"inter_mag_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "    \n",
    "    node_process_data = node(\n",
    "        process_mag_data,\n",
    "        inputs=f\"inter_mag_{ts}\",\n",
    "        outputs=f\"primary_mag_rtn_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "    \n",
    "    node_extract_features = node(\n",
    "        extract_features,\n",
    "        inputs=[f\"primary_mag_rtn_{ts}\", \"params:tau\", \"params:extract_params\"],\n",
    "        outputs=f\"feature_tau_{tau}\",\n",
    "        name=f\"extract_{sat_id}_features\",\n",
    "    )\n",
    "\n",
    "    nodes = [\n",
    "        node_download_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "        node_extract_features,\n",
    "    ]\n",
    "\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:tau\": \"params:tau\",\n",
    "            \"params:extract_params\": \"params:jno_1s_params\",\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "        },\n",
    "    )\n",
    "    return pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_planet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
