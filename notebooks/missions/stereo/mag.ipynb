{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: STEREO Magnetic field data pipeline\n",
    "---\n",
    "\n",
    "STEREO magnetic field is already in RTN coordinates, so no need to transform it.\n",
    "\n",
    "Download data using `pyspedas`, but load it using `pycdfpp` (using `pyspedas` to load the data directly into `xarray` is very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/stereo/mag\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['SPEDAS_DATA_DIR'] = f\"{os.environ['HOME']}/data\"\n",
    "import pyspedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def download_mag_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    probe: str = \"a\",\n",
    ") -> Iterable[str]:\n",
    "    trange = [start, end]\n",
    "    files = pyspedas.stereo.mag(trange, downloadonly=True, probe=probe)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.basic import cdf2pl\n",
    "from pipe import select\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_mag_data(\n",
    "    raw_data: Iterable[str] = None, # List of CDF files\n",
    "    ts: str = \"1s\",  # time resolution\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Downsample the data to a given time resolution\n",
    "    - Applying naming conventions for columns\n",
    "    \"\"\"\n",
    "    every = pandas.Timedelta(ts)\n",
    "    period = 2 * every\n",
    "\n",
    "    df: pl.LazyFrame = pl.concat(raw_data | pmap(cdf2pl, var_name=\"BFIELD\"))\n",
    "\n",
    "    return (\n",
    "        df.pipe(resample, every=every, period=period)\n",
    "        .rename(\n",
    "            {\n",
    "                \"BFIELD_0\": \"b_r\",\n",
    "                \"BFIELD_1\": \"b_t\",\n",
    "                \"BFIELD_2\": \"b_n\",\n",
    "                \"BFIELD_3\": \"b_mag\",\n",
    "            }\n",
    "        )\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_mag_data(\n",
    "    raw_data: pl.DataFrame,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = None,\n",
    ") -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Corresponding to primary data layer, where source data models are transformed into domain data models\n",
    "\n",
    "    - Partitioning data, for the sake of memory\n",
    "    \"\"\"\n",
    "    return partition_data_by_year(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_mag_data_pipeline(\n",
    "    sat_id,\n",
    "    ts: str = \"1s\",  # time resolution,\n",
    "    tau: str = \"60s\",  # time window\n",
    "    **kwargs,\n",
    ") -> Pipeline:\n",
    "    node_download_data = node(\n",
    "        download_mag_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"raw_mag_files\",\n",
    "        name=f\"download_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_mag_data,\n",
    "        inputs=dict(\n",
    "            raw_data=f\"raw_mag_files\",\n",
    "        ),\n",
    "        outputs=f\"inter_mag_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_process_data = node(\n",
    "        process_mag_data,\n",
    "        inputs=f\"inter_mag_{ts}\",\n",
    "        outputs=f\"primary_mag_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_magnetic_field_data\",\n",
    "    )\n",
    "\n",
    "    node_extract_features = node(\n",
    "        extract_features,\n",
    "        inputs=[f\"primary_mag_{ts}\", \"params:tau\", \"params:extract_params\"],\n",
    "        outputs=f\"feature_tau_{tau}\",\n",
    "        name=f\"extract_{sat_id}_features\",\n",
    "    )\n",
    "\n",
    "    nodes = [\n",
    "        node_download_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "        node_extract_features,\n",
    "    ]\n",
    "\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "            \"params:tau\": \"params:tau\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
