{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: STEREO Magnetic field data pipeline\n",
    "---\n",
    "\n",
    "STEREO magnetic field is already in RTN coordinates, so no need to transform it.\n",
    "\n",
    "Download data using `pyspedas`, but load it using `pycdfpp` (using `pyspedas` to load the data directly into `xarray` is very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import timedelta\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from ids_finder.utils.cdf import cdf2pl\n",
    "from ids_finder.utils.basic import pmap, resample, partition_data_by_year\n",
    "from ids_finder.utils.polars import create_partitions\n",
    "from ids_finder.pipelines.default.data_mag import create_pipeline_template\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from typing import Dict, Iterable, Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/stereo/mag\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ['SPEDAS_DATA_DIR'] = str(Path.home() / 'data')\n",
    "import pyspedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def download_data(\n",
    "    start,\n",
    "    end,\n",
    "    probe: str = \"a\",\n",
    "    datatype = '8hz',\n",
    ") -> Iterable[str]:\n",
    "    \"List of CDF files\"\n",
    "    trange = [start, end]\n",
    "    files = pyspedas.stereo.mag(trange, probe=probe, datatype=datatype, downloadonly=True)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    start,\n",
    "    end,\n",
    "    datatype = '8hz',\n",
    "    probe: str = \"a\",\n",
    "):\n",
    "    files = download_data(start, end, probe, datatype)\n",
    "    var_names=\"BFIELD\"\n",
    "    return pl.concat(files | pmap(cdf2pl, var_names=var_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_data(\n",
    "    raw_data,\n",
    "    var_names=\"BFIELD\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "    - Applying naming conventions for columns\n",
    "    \"\"\"\n",
    "    load_func = partial(cdf2pl, var_names=var_names)\n",
    "\n",
    "    return create_partitions(raw_data, load_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def process_data(\n",
    "    raw_data: Dict[str, Callable[..., pl.LazyFrame]],\n",
    "    ts,  # time resolution, in seconds\n",
    "):\n",
    "    every = timedelta(seconds=ts)\n",
    "    period = every\n",
    "\n",
    "    data: pl.LazyFrame = pl.concat(\n",
    "        resample(func(), every=every, period=period) for func in raw_data.values()\n",
    "    )\n",
    "    \n",
    "    return data.unique(\"time\").pipe(partition_data_by_year)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_pipeline(sat_id=\"STA\", source=\"MAG\"):\n",
    "    return create_pipeline_template(\n",
    "        sat_id=sat_id,\n",
    "        source=source,\n",
    "        load_data_fn=download_data,\n",
    "        preprocess_data_fn=preprocess_data,\n",
    "        process_data_fn=process_data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: one can also use `speasy` to download data, however this is slower for `STEREO` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "sat_fgm_product = cda_tree.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD\n",
    "sat_fgm_product = 'cda/STA_L1_MAG_RTN/BFIELD'\n",
    "products = [sat_fgm_product]\n",
    "\n",
    "dataset = spz.get_data(products, test_trange, disable_proxy=True)\n",
    "sat_fgm_data  = dataset[0]\n",
    "data_preview(sat_fgm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data in a background thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\n",
    "@threaded\n",
    "def download_data(products, trange):\n",
    "    logger.info(\"Downloading data\")\n",
    "    spz.get_data(products, trange, disable_proxy=True)\n",
    "    logger.info(\"Data downloaded\")\n",
    "    \n",
    "download_data(products, trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speasy as spz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cda_tree: spz.SpeasyIndex = spz.inventories.tree.cda\n",
    "product = cda_tree.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN\n",
    "\n",
    "logger.info(product.description)\n",
    "logger.info(product.ID)\n",
    "logger.info(product.BFIELD.CATDESC)\n",
    "logger.info(product.BFIELD.spz_uid())\n",
    "\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.\n",
    "# spz.inventories.data_tree.cda.STEREO.STEREOA.IMPACT_MAG.STA_LB_MAG_RTN.description\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.MAGFLAGUC.CATDESC\n",
    "spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD.CATDESC\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_planet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
