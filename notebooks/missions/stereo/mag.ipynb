{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: STEREO Magnetic field data pipeline\n",
    "---\n",
    "\n",
    "STEREO magnetic field is already in RTN coordinates, so no need to transform it.\n",
    "\n",
    "Download data using `pyspedas`, but load it using `pycdfpp` (using `pyspedas` to load the data directly into `xarray` is very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import timedelta\n",
    "\n",
    "import polars as pl\n",
    "import pandas\n",
    "\n",
    "from kedro.pipeline import Pipeline, node\n",
    "from kedro.pipeline.modular_pipeline import pipeline\n",
    "\n",
    "from typing import Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| default_exp pipelines/stereo/mag\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.environ['SPEDAS_DATA_DIR'] = f\"{os.environ['HOME']}/data\"\n",
    "import pyspedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from ids_finder.utils.basic import cdf2pl, pmap\n",
    "\n",
    "def download_data(\n",
    "    start,\n",
    "    end,\n",
    "    probe: str = \"a\",\n",
    "    datatype = None,\n",
    ") -> Iterable[str]:\n",
    "    \"List of CDF files\"\n",
    "    trange = [start, end]\n",
    "    files = pyspedas.stereo.mag(trange, probe=probe, datatype=datatype, downloadonly=True)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    start,\n",
    "    end,\n",
    "    datatype = None,\n",
    "    probe: str = \"a\",\n",
    "):\n",
    "    data = download_data(start, end, probe, datatype)\n",
    "    return pl.concat(data | pmap(cdf2pl, var_name=\"BFIELD\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.basic import resample\n",
    "from pipe import select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def preprocess_data(\n",
    "    raw_data: pl.LazyFrame,\n",
    "    ts: str = \"1s\",  # time resolution\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Downsample the data to a given time resolution\n",
    "    - Applying naming conventions for columns\n",
    "    \"\"\"\n",
    "    every = pandas.Timedelta(ts)\n",
    "    period = 2 * every\n",
    "\n",
    "    return (\n",
    "        raw_data.pipe(resample, every=every, period=period)\n",
    "        .rename(\n",
    "            {\n",
    "                \"BFIELD_0\": \"b_r\",\n",
    "                \"BFIELD_1\": \"b_t\",\n",
    "                \"BFIELD_2\": \"b_n\",\n",
    "                \"BFIELD_3\": \"b_mag\",\n",
    "            }\n",
    "        )\n",
    "        .collect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.basic import partition_data_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_data(\n",
    "    raw_data: pl.DataFrame,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = None,\n",
    ") -> dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Corresponding to primary data layer, where source data models are transformed into domain data models\n",
    "\n",
    "    - Partitioning data, for the sake of memory\n",
    "    \"\"\"\n",
    "    return partition_data_by_year(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from ids_finder.core.pipeline import extract_features\n",
    "from ids_finder.pipelines.default.data_mag import create_pipeline_template\n",
    "\n",
    "\n",
    "def create_pipeline(sat_id=\"STA\", source=\"MAG\"):\n",
    "    return create_pipeline_template(\n",
    "        sat_id=sat_id,\n",
    "        source=source,\n",
    "        load_data_fn=load_data,\n",
    "        preprocess_data_fn=preprocess_data,\n",
    "        process_data_fn=process_data,\n",
    "        extract_features_fn=extract_features,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: one can also use `speasy` to download data, however this is slower for `STEREO` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "sat_fgm_product = cda_tree.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD\n",
    "sat_fgm_product = 'cda/STA_L1_MAG_RTN/BFIELD'\n",
    "products = [sat_fgm_product]\n",
    "\n",
    "dataset = spz.get_data(products, test_trange, disable_proxy=True)\n",
    "sat_fgm_data  = dataset[0]\n",
    "data_preview(sat_fgm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data in a background thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\n",
    "@threaded\n",
    "def download_data(products, trange):\n",
    "    logger.info(\"Downloading data\")\n",
    "    spz.get_data(products, trange, disable_proxy=True)\n",
    "    logger.info(\"Data downloaded\")\n",
    "    \n",
    "download_data(products, trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speasy as spz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cda_tree: spz.SpeasyIndex = spz.inventories.tree.cda\n",
    "product = cda_tree.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN\n",
    "\n",
    "logger.info(product.description)\n",
    "logger.info(product.ID)\n",
    "logger.info(product.BFIELD.CATDESC)\n",
    "logger.info(product.BFIELD.spz_uid())\n",
    "\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.\n",
    "# spz.inventories.data_tree.cda.STEREO.STEREOA.IMPACT_MAG.STA_LB_MAG_RTN.description\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.MAGFLAGUC.CATDESC\n",
    "spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD.CATDESC\n",
    "# spz.inventories.data_tree.cda.STEREO.Ahead.IMPACT_MAG.STA_L1_MAG_RTN.BFIELD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_planet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
