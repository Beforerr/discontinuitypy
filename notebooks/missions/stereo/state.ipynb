{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State data pipeline\n",
    "\n",
    "For STEREO's mission, We use 1-hour averaged merged data from [COHOWeb](https://omniweb.gsfc.nasa.gov/coho/).\n",
    "\n",
    "See [STEREO ASCII merged data](https://spdf.gsfc.nasa.gov/pub/data/stereo/ahead/l2/merged/aareadme_sta) and one sample file [here](https://spdf.gsfc.nasa.gov/pub/data/stereo/ahead/l2/merged/stereoa2011.asc\n",
    "\n",
    "Plasma in RTN (Radial-Tangential-Normal) coordinate system\n",
    "- Proton Flow Speed, km/sec\n",
    "- Proton Flow Elevation Angle/Latitude, deg.\n",
    "- Proton Flow Azimuth Angle/Longitude, deg.\n",
    "- Proton Density, n/cc\n",
    "- Proton Temperature, K)\n",
    "\n",
    "Notes\n",
    "- Note1: There is a big gap 2014/12/16 - 2015/07/20 in plasma data\n",
    "- Note2: There is a big gap 2015/03/21 - 2015/07/09 and 2015/10/27 - 2015/11/15 in mag data\n",
    "- Note that for missing data, fill values consisting of a blank followed by 9's which together constitute the format are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pipelines/stearo/state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pooch\n",
    "from pipe import select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def download_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    ") -> List[str]:\n",
    "    download = partial(pooch.retrieve, known_hash=None)\n",
    "\n",
    "    start_time = pandas.Timestamp(start)\n",
    "    end_time = pandas.Timestamp(end)\n",
    "\n",
    "    url = \"https://spdf.gsfc.nasa.gov/pub/data/stereo/ahead/l2/merged/stereoa{year}.asc\"\n",
    "\n",
    "    files = list(\n",
    "        range(start_time.year, end_time.year + 1)\n",
    "        | select(lambda x: url.format(year=x))\n",
    "        | select(download)\n",
    "    )\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "headers = \"\"\"Year\n",
    "DOY\n",
    "Hour\n",
    "Radial Distance, AU\n",
    "HGI Lat. of the S/C\n",
    "HGI Long. of the S/C\n",
    "IMF BR, nT (RTN)\n",
    "IMF BT, nT (RTN)\n",
    "IMF BN, nT (RTN)\n",
    "IMF B Scalar, nT\n",
    "SW Plasma Speed, km/s\n",
    "SW Lat. Angle RTN, deg.\n",
    "SW Long. Angle RTN, deg.\n",
    "SW Plasma Density, N/cm^3\n",
    "SW Plasma Temperature, K\n",
    "1.8-3.6 MeV H flux,LET\n",
    "4.0-6.0 MeV H flux,LET\n",
    "6.0-10.0 MeV H flux, LET\n",
    "10.0-12.0 MeV H flux,LET\n",
    "13.6-15.1 MeV H flux, HET\n",
    "14.9-17.1 MeV H flux, HET\n",
    "17.0-19.3 MeV H flux, HET\n",
    "20.8-23.8 MeV H flux, HET\n",
    "23.8-26.4 MeV H flux, HET\n",
    "26.3-29.7 MeV H flux, HET\n",
    "29.5-33.4 MeV H flux, HET\n",
    "33.4-35.8 MeV H flux, HET\n",
    "35.5-40.5 MeV H flux, HET\n",
    "40.0-60.0 MeV H flux, HET\n",
    "60.0-100.0 MeV H flux, HET\n",
    "0.320-0.452 MeV H flux, SIT\n",
    "0.452-0.64 MeV H flux, SIT\n",
    "0.640-0.905 MeV H flux, SIT\n",
    "0.905-1.28 MeV H flux, SIT\n",
    "1.280-1.81 MeV H flux, SIT\n",
    "1.810-2.56 MeV H flux, SIT\n",
    "2.560-3.62 MeV H flux, SIT\"\"\"\n",
    "\n",
    "def load_state_data(\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    - Downloading data\n",
    "    - Reading data into a proper data structure, like dataframe.\n",
    "        - Parsing original data (dealing with delimiters, missing values, etc.)\n",
    "    \"\"\"\n",
    "    files = download_state_data(start, end)\n",
    "    \n",
    "    labels = headers.split(\"\\n\")\n",
    "    missing_values = [\"999.99\", \"9999.9\", \"9999999.\"]\n",
    "\n",
    "    df = pl.concat(\n",
    "        files\n",
    "        | pmap(\n",
    "            pandas.read_csv,\n",
    "            delim_whitespace=True,\n",
    "            names=labels,\n",
    "            na_values=missing_values,\n",
    "        )\n",
    "        | select(pl.from_pandas)\n",
    "    )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_state_data(\n",
    "    raw_data: pl.DataFrame,\n",
    "    ts: str = None,  # time resolution\n",
    "    coord: str = None,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the raw dataset (only minor transformations)\n",
    "\n",
    "    - Parsing and typing data (like from string to datetime for time columns)\n",
    "    - Changing storing format (like from `csv` to `parquet`)\n",
    "    \"\"\"\n",
    "\n",
    "    return raw_data.with_columns(\n",
    "        time=(\n",
    "            pl.datetime(pl.col(\"Year\"), month=1, day=1)\n",
    "            + pl.duration(days=pl.col(\"DOY\") - 1, hours=pl.col(\"Hour\"))\n",
    "        ).dt.cast_time_unit(\"ns\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processs state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def convert_state_to_rtn(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Convert state data to RTN coordinates\"\"\"\n",
    "    plasma_speed = pl.col(\"plasma_speed\")\n",
    "    sw_elevation = pl.col(\"sw_elevation\").radians()\n",
    "    sw_azimuth = pl.col(\"sw_azimuth\").radians()\n",
    "    return df.with_columns(\n",
    "        sw_vel_r=plasma_speed * sw_elevation.cos() * sw_azimuth.cos(),\n",
    "        sw_vel_t=plasma_speed * sw_elevation.cos() * sw_azimuth.sin(),\n",
    "        sw_vel_n=plasma_speed * sw_elevation.sin(),\n",
    "    ).drop([\"sw_elevation\", \"sw_azimuth\"])\n",
    "\n",
    "\n",
    "STATE_POSITION_COLS = [\n",
    "    \"Radial Distance, AU\",\n",
    "    \"HGI Lat. of the S/C\",\n",
    "    \"HGI Long. of the S/C\",\n",
    "]\n",
    "\n",
    "STATE_PLASMA_COLS = [\n",
    "    \"SW Plasma Speed, km/s\",\n",
    "    \"SW Lat. Angle RTN, deg.\",\n",
    "    \"SW Long. Angle RTN, deg.\",\n",
    "    \"SW Plasma Density, N/cm^3\",\n",
    "    \"SW Plasma Temperature, K\",\n",
    "]\n",
    "\n",
    "columns_name_mapping = {\n",
    "    \"SW Plasma Speed, km/s\": \"plasma_speed\",\n",
    "    \"SW Lat. Angle RTN, deg.\": \"sw_elevation\",\n",
    "    \"SW Long. Angle RTN, deg.\": \"sw_azimuth\",\n",
    "    \"SW Plasma Density, N/cm^3\": \"plasma_density\",\n",
    "    \"SW Plasma Temperature, K\": \"plasma_temperature\",\n",
    "    \"Radial Distance, AU\": \"radial_distance\",\n",
    "}\n",
    "\n",
    "\n",
    "def process_state_data(\n",
    "    df: pl.DataFrame, columns: list[str] = STATE_POSITION_COLS + STATE_PLASMA_COLS\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Corresponding to primary data layer, where source data models are transformed into domain data models\n",
    "\n",
    "    - Applying naming conventions for columns\n",
    "    - Transforming data to RTN (Radial-Tangential-Normal) coordinate system\n",
    "    - Discarding unnecessary columns\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        df.select(\"time\", *columns)\n",
    "        .rename(columns_name_mapping)\n",
    "        .pipe(convert_state_to_rtn)\n",
    "        .rename(\n",
    "            {\n",
    "                \"sw_vel_r\": \"v_x\",\n",
    "                \"sw_vel_t\": \"v_y\",\n",
    "                \"sw_vel_n\": \"v_z\",\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_state_data_pipeline(\n",
    "    sat_id = 'sta',\n",
    "    ts: str = '1h',  # time resolution\n",
    "    **kwargs\n",
    ") -> Pipeline:\n",
    "    \n",
    "    node_load_data = node(\n",
    "        load_state_data,\n",
    "        inputs=dict(\n",
    "            start=\"params:start_date\",\n",
    "            end=\"params:end_date\",\n",
    "        ),\n",
    "        outputs=f\"raw_state\",\n",
    "        name=f\"load_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "\n",
    "    node_preprocess_data = node(\n",
    "        preprocess_state_data,\n",
    "        inputs=dict(\n",
    "            raw_data=f\"raw_state\",\n",
    "        ),\n",
    "        outputs=f\"inter_state_{ts}\",\n",
    "        name=f\"preprocess_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    node_process_data = node(\n",
    "        process_state_data,\n",
    "        inputs=f\"inter_state_{ts}\",\n",
    "        outputs=f\"primary_state_{ts}\",\n",
    "        name=f\"process_{sat_id.upper()}_state_data\",\n",
    "    )\n",
    "    \n",
    "    nodes = [\n",
    "        node_load_data,\n",
    "        node_preprocess_data,\n",
    "        node_process_data,\n",
    "    ]\n",
    "    pipelines = pipeline(\n",
    "        nodes,\n",
    "        namespace=sat_id,\n",
    "        parameters={\n",
    "            \"params:start_date\": \"params:jno_start_date\",\n",
    "            \"params:end_date\": \"params:jno_end_date\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
