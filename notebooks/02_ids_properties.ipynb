{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: ID properties\n",
    "subtitle: Full feature extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core/propeties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/19/23 00:30:32] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook    <a href=\"file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         mode. Use `tqdm.tqdm` instead to force console mode <span style=\"font-weight: bold\">(</span>e.g. in jupyter   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         console<span style=\"font-weight: bold\">)</span>                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/19/23 00:30:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook    \u001b]8;id=931555;file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=634934;file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         mode. Use `tqdm.tqdm` instead to force console mode \u001b[1m(\u001b[0me.g. in jupyter   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         console\u001b[1m)\u001b[0m                                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "#| code-summary: \"Import all the packages needed for the project\"\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "from ids_finder.utils.basic import *\n",
    "import polars as pl\n",
    "import xarray as xr\n",
    "import pyarrow as pa\n",
    "\n",
    "try:\n",
    "    import modin.pandas as pd\n",
    "    import modin.pandas as mpd\n",
    "    from modin.config import ProgressBar\n",
    "    ProgressBar.enable()\n",
    "except ImportError:\n",
    "    import pandas as pd\n",
    "import pandas\n",
    "    \n",
    "import numpy as np\n",
    "from xarray_einstats import linalg\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "import pdpipe as pdp\n",
    "from pdpipe.util import out_of_place_col_insert\n",
    "from multipledispatch import dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dispatch(object, xr.DataArray)\n",
    "def get_candidate_data(\n",
    "    candidate, data, neighbor: int = 0\n",
    ") -> xr.DataArray:\n",
    "    duration = candidate[\"tstop\"] - candidate[\"tstart\"]\n",
    "    offset = neighbor * duration\n",
    "    temp_tstart = candidate[\"tstart\"] - offset\n",
    "    temp_tstop = candidate[\"tstop\"] + offset\n",
    "\n",
    "    return data.sel(time=slice(temp_tstart, temp_tstop))\n",
    "\n",
    "\n",
    "@dispatch(object, pl.DataFrame)\n",
    "def get_candidate_data(\n",
    "    candidate, data, neighbor: int = 0, bcols=[\"BX\", \"BY\", \"BZ\"]\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Notes\n",
    "    -----\n",
    "    much slower than `get_candidate_data_xr`\n",
    "    \"\"\"\n",
    "    duration = candidate[\"tstart\"] - candidate[\"tstop\"]\n",
    "    offset = neighbor * duration\n",
    "    temp_tstart = candidate[\"tstart\"] - offset\n",
    "    temp_tstop = candidate[\"tstop\"] + offset\n",
    "\n",
    "    temp_data = data.filter(pl.col(\"time\").is_between(temp_tstart, temp_tstop))\n",
    "\n",
    "    return df2ts(temp_data, bcols, attrs={\"units\": \"nT\"})\n",
    "\n",
    "\n",
    "def get_candidates(candidates: pd.DataFrame, candidate_type=None, num: int = 4):\n",
    "    if candidate_type is not None:\n",
    "        _candidates = candidates[candidates[\"type\"] == candidate_type]\n",
    "    else:\n",
    "        _candidates = candidates\n",
    "\n",
    "    # Sample a specific number of candidates if num is provided and it's less than the total number\n",
    "    if num < len(_candidates):\n",
    "        logger.info(\n",
    "            f\"Sampling {num} {candidate_type} candidates out of {len(_candidates)}\"\n",
    "        )\n",
    "        return _candidates.sample(num)\n",
    "    else:\n",
    "        return _candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of duration\n",
    "- Define $d^* = \\max( | dB / dt | ) $, and then define time interval where $| dB/dt |$ decreases to $d^*/4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "THRESHOLD_RATIO  = 1/4\n",
    "\n",
    "def calc_duration(vec: xr.DataArray, threshold_ratio=THRESHOLD_RATIO) -> pandas.Series:\n",
    "    # NOTE: gradient calculated at the edge is not reliable.\n",
    "    vec_diff = vec.differentiate(\"time\", datetime_unit=\"s\").isel(time=slice(1,-1))\n",
    "    vec_diff_mag = linalg.norm(vec_diff, dims='v_dim')\n",
    "\n",
    "    # Determine d_star based on trend\n",
    "    if vec_diff_mag.isnull().all():\n",
    "        raise ValueError(\"The differentiated vector magnitude contains only NaN values. Cannot compute duration.\")\n",
    "    \n",
    "    d_star_index = vec_diff_mag.argmax(dim=\"time\")\n",
    "    d_star = vec_diff_mag[d_star_index]\n",
    "    d_time = vec_diff_mag.time[d_star_index]\n",
    "    \n",
    "    threshold = d_star * threshold_ratio\n",
    "\n",
    "    start_time, end_time = find_start_end_times(vec_diff_mag, d_time, threshold)\n",
    "\n",
    "    dict = {\n",
    "        'd_star': d_star.item(),\n",
    "        'd_time': d_time.values,\n",
    "        'threshold': threshold.item(),\n",
    "        'd_tstart': start_time,\n",
    "        'd_tstop': end_time,\n",
    "    }\n",
    "\n",
    "    return pandas.Series(dict)\n",
    "\n",
    "def calc_d_duration(vec: xr.DataArray, d_time, threshold) -> pd.Series:\n",
    "    vec_diff = vec.differentiate(\"time\", datetime_unit=\"s\")\n",
    "    vec_diff_mag = linalg.norm(vec_diff, dims='v_dim')\n",
    "\n",
    "    start_time, end_time = find_start_end_times(vec_diff_mag, d_time, threshold)\n",
    "\n",
    "    return pandas.Series({\n",
    "        'd_tstart': start_time,\n",
    "        'd_tstop': end_time,\n",
    "    })\n",
    " \n",
    "def find_start_end_times(vec_diff_mag: xr.DataArray, d_time, threshold) -> tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    # Determine start time\n",
    "    pre_vec_mag = vec_diff_mag.sel(time=slice(None, d_time))\n",
    "    start_time = get_time_from_condition(pre_vec_mag, threshold, \"last_below\")\n",
    "\n",
    "    # Determine stop time\n",
    "    post_vec_mag = vec_diff_mag.sel(time=slice(d_time, None))\n",
    "    end_time = get_time_from_condition(post_vec_mag, threshold, \"first_below\")\n",
    "\n",
    "    return start_time, end_time\n",
    "\n",
    "\n",
    "def get_time_from_condition(vec: xr.DataArray, threshold, condition_type) -> pd.Timestamp:\n",
    "    if condition_type == \"first_below\":\n",
    "        condition = vec < threshold\n",
    "        index_choice = 0\n",
    "    elif condition_type == \"last_below\":\n",
    "        condition = vec < threshold\n",
    "        index_choice = -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown condition_type: {condition_type}\")\n",
    "\n",
    "    where_result = np.where(condition)[0]\n",
    "\n",
    "    if len(where_result) > 0:\n",
    "        return vec.time[where_result[index_choice]].values\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_candidate_duration(candidate: pd.Series, data) -> pd.Series:\n",
    "    try:\n",
    "        candidate_data = get_candidate_data(candidate, data)\n",
    "        return calc_duration(candidate_data)\n",
    "    except Exception as e:\n",
    "        # logger.debug(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\") # can not be serialized\n",
    "        print(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\")\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum variance analysis (MVA) features\n",
    "\n",
    "To ensure the accuracy of MVA, only when the ratio of the middle to the minimum eigenvalue (labeled QMVA for simplicity) is larger than 3 are the results used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def minvar(data):\n",
    "    \"\"\"\n",
    "    see `pyspedas.cotrans.minvar`\n",
    "    This program computes the principal variance directions and variances of a\n",
    "    vector quantity as well as the associated eigenvalues.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data:\n",
    "        Vxyz, an (npoints, ndim) array of data(ie Nx3)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vrot:\n",
    "        an array of (npoints, ndim) containing the rotated data in the new coordinate system, ijk.\n",
    "        Vi(maximum direction)=vrot[0,:]\n",
    "        Vj(intermediate direction)=vrot[1,:]\n",
    "        Vk(minimum variance direction)=Vrot[2,:]\n",
    "    v:\n",
    "        an (ndim,ndim) array containing the principal axes vectors\n",
    "        Maximum variance direction eigenvector, Vi=v[*,0]\n",
    "        Intermediate variance direction, Vj=v[*,1] (descending order)\n",
    "    w:\n",
    "        the eigenvalues of the computation\n",
    "    \"\"\"\n",
    "\n",
    "    #  Min var starts here\n",
    "    # data must be Nx3\n",
    "    vecavg = np.nanmean(np.nan_to_num(data, nan=0.0), axis=0)\n",
    "\n",
    "    mvamat = np.zeros((3, 3))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            mvamat[i, j] = np.nanmean(np.nan_to_num(data[:, i] * data[:, j], nan=0.0)) - vecavg[i] * vecavg[j]\n",
    "\n",
    "    # Calculate eigenvalues and eigenvectors\n",
    "    w, v = np.linalg.eigh(mvamat, UPLO='U')\n",
    "\n",
    "    # Sorting to ensure descending order\n",
    "    w = np.abs(w)\n",
    "    idx = np.flip(np.argsort(w))\n",
    "\n",
    "    # IDL compatability\n",
    "    if True:\n",
    "        if np.sum(w) == 0.0:\n",
    "            idx = [0, 2, 1]\n",
    "\n",
    "    w = w[idx]\n",
    "    v = v[:, idx]\n",
    "\n",
    "    # Rotate intermediate var direction if system is not Right Handed\n",
    "    YcrossZdotX = v[0, 0] * (v[1, 1] * v[2, 2] - v[2, 1] * v[1, 2])\n",
    "    if YcrossZdotX < 0:\n",
    "        v[:, 1] = -v[:, 1]\n",
    "        # v[:, 2] = -v[:, 2] # Should not it is being flipped at Z-axis?\n",
    "\n",
    "    # Ensure minvar direction is along +Z (for FAC system)\n",
    "    if v[2, 2] < 0:\n",
    "        v[:, 2] = -v[:, 2]\n",
    "        v[:, 1] = -v[:, 1]\n",
    "\n",
    "    vrot = np.array([np.dot(row, v) for row in data])\n",
    "\n",
    "    return vrot, v, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def mva_features(data: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute MVA features based on the given data array.\n",
    "\n",
    "    Parameters:\n",
    "    - data (np.ndarray): Input data\n",
    "\n",
    "    Returns:\n",
    "    - List: Computed features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute variance properties\n",
    "    vrot, v, w = minvar(data)\n",
    "\n",
    "    # Maximum variance direction eigenvector\n",
    "    Vl = v[:, 0]\n",
    "    Vm = v[:, 1]\n",
    "    Vn = v[:, 2]\n",
    "\n",
    "    vec_mag = np.linalg.norm(vrot, axis=1)\n",
    "    \n",
    "    # Compute changes in each component of B_rot\n",
    "    dvec = [vrot[0, i] - vrot[-1, i] for i in range(3)]\n",
    "    \n",
    "    # Compute mean values\n",
    "    vec_mag_mean = np.mean(vec_mag)\n",
    "    vec_n_mean = np.mean(vrot[:, 2])\n",
    "    VnOverVmag = vec_n_mean / vec_mag_mean\n",
    "\n",
    "    # Compute relative changes in magnitude\n",
    "    dvec_mag = vec_mag[-1] - vec_mag[0]\n",
    "    dBOverB = np.abs(dvec_mag / vec_mag_mean)\n",
    "    dBOverB_max = (np.max(vec_mag) - np.min(vec_mag)) / vec_mag_mean\n",
    "\n",
    "    output_names = [\n",
    "        \"Vl_x\", \"Vl_y\", \"Vl_z\",\n",
    "        \"Vn_x\", \"Vn_y\", \"Vn_z\",\n",
    "        \"eig0\", \"eig1\", \"eig2\", \n",
    "        'Q_mva',\n",
    "        'b_mag', 'b_n', 'db_mag', 'bn_over_b', 'db_over_b', 'db_over_b_max', 'db_l', 'db_m', 'db_n']\n",
    "    \n",
    "    results = [\n",
    "        Vl[0], Vl[1], Vl[2],\n",
    "        Vn[0], Vn[1], Vn[2],\n",
    "        w[0], w[1], w[2],\n",
    "        w[1] / w[2],\n",
    "        vec_mag_mean,\n",
    "        vec_n_mean,\n",
    "        dvec_mag,\n",
    "        VnOverVmag, \n",
    "        dBOverB,\n",
    "        dBOverB_max,\n",
    "        dvec[0], dvec[1], dvec[2]\n",
    "    ]\n",
    "\n",
    "    return results, output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_candidate_mva_features(candidate, data: xr.DataArray):\n",
    "    results, output_names = mva_features(\n",
    "        data.sel(time=slice(candidate[\"d_tstart\"], candidate[\"d_tstop\"])).to_numpy()\n",
    "    )\n",
    "\n",
    "    return pandas.Series(results, index=output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from fastcore.test import *\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = np.random.rand(100, 3)  # 100 time points, 3-dimensional data\n",
    "# Call the mva_features function\n",
    "features = mva_features(data)\n",
    "_features = [0.3631060892452051, 0.8978455426527485, -0.24905290500542857, 0.09753158579102299, 0.086943767300213, 0.07393142040422575, 1.1760056390752571, 0.9609421690770317, 0.6152039820297959, -0.5922397773398479, 0.6402091632847049, 0.61631157045453, 1.2956351134759623, 0.19091785005728523, 0.5182488424049534, 0.4957624347593598]\n",
    "test_eq(features, _features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field rotation angles\n",
    "The PDF of the field rotation angles across the solar-wind IDs is well fitted by the exponential function exp(−θ/)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_data_at_times(data: xr.DataArray, times) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Select data at specified times.\n",
    "    \"\"\"\n",
    "    # Use xarray's selection capability if data supports it\n",
    "    return data.sel(time=times, method=\"nearest\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_rotation_angle(v1, v2):\n",
    "    \"\"\"\n",
    "    Computes the rotation angle between two vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    - v1: The first vector(s).\n",
    "    - v2: The second vector(s).\n",
    "    \"\"\"\n",
    "    \n",
    "    if v1.shape != v2.shape:\n",
    "        raise ValueError(\"Vectors must have the same shape.\")\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    v1_u = v1 / np.linalg.norm(v1, axis=-1, keepdims=True)\n",
    "    v2_u = v2 / np.linalg.norm(v2, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Calculate the cosine of the angle for each time step\n",
    "    cosine_angle = np.sum(v1_u * v2_u, axis=-1)\n",
    "    \n",
    "    # Clip the values to handle potential floating point errors\n",
    "    cosine_angle = np.clip(cosine_angle, -1, 1)\n",
    "    \n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    # Convert the angles from radians to degrees\n",
    "    return np.degrees(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_events_rotation_angle(events, data: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Computes the rotation angle(s) at two different time steps.\n",
    "    \"\"\"\n",
    "    tstart = events['d_tstart'].to_numpy()\n",
    "    tstop = events['d_tstop'].to_numpy()\n",
    "\n",
    "    vecs_before = get_data_at_times(data, tstart)\n",
    "    vecs_after = get_data_at_times(data, tstop)\n",
    "\n",
    "    rotation_angles = calc_rotation_angle(vecs_before, vecs_after)\n",
    "    return rotation_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_normal_direction(v1, v2, normalize=True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the normal direction of two vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v1 : array_like \n",
    "        The first vector(s).\n",
    "    v2 : array_like \n",
    "        The second vector(s).\n",
    "    \"\"\"\n",
    "    c = np.cross(v1, v2)\n",
    "    return c / np.linalg.norm(c, axis=-1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_events_normal_direction(events, data: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Computes the normal directions(s) at two different time steps.\n",
    "    \"\"\"\n",
    "    tstart = events['d_tstart'].to_numpy()\n",
    "    tstop = events['d_tstop'].to_numpy()\n",
    "\n",
    "    vecs_before = get_data_at_times(data, tstart)\n",
    "    vecs_after = get_data_at_times(data, tstop)\n",
    "\n",
    "    normal_directions = calc_normal_direction(vecs_before, vecs_after)\n",
    "    # need to convert to list first, as only 1D array is supported\n",
    "    return normal_directions.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patch `pdp.ApplyToRows` to work with `modin` and `xorbits` DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _transform(self: pdp.ApplyToRows, X, verbose):\n",
    "    new_cols = X.apply(self._func, axis=1)\n",
    "    if isinstance(new_cols, (pd.Series, pandas.Series)):\n",
    "        loc = len(X.columns)\n",
    "        if self._follow_column:\n",
    "            loc = X.columns.get_loc(self._follow_column) + 1\n",
    "        return out_of_place_col_insert(\n",
    "            X=X, series=new_cols, loc=loc, column_name=self._colname\n",
    "        )\n",
    "    if isinstance(new_cols, (mpd.DataFrame, pandas.DataFrame)):\n",
    "        sorted_cols = sorted(list(new_cols.columns))\n",
    "        new_cols = new_cols[sorted_cols]\n",
    "        if self._follow_column:\n",
    "            inter_X = X\n",
    "            loc = X.columns.get_loc(self._follow_column) + 1\n",
    "            for colname in new_cols.columns:\n",
    "                inter_X = out_of_place_col_insert(\n",
    "                    X=inter_X,\n",
    "                    series=new_cols[colname],\n",
    "                    loc=loc,\n",
    "                    column_name=colname,\n",
    "                )\n",
    "                loc += 1\n",
    "            return inter_X\n",
    "        assign_map = {\n",
    "            colname: new_cols[colname] for colname in new_cols.columns\n",
    "        }\n",
    "        return X.assign(**assign_map)\n",
    "    raise TypeError(  # pragma: no cover\n",
    "        \"Unexpected type generated by applying a function to a DataFrame.\"\n",
    "        \" Only Series and DataFrame are allowed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipelines` Class for processing IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class IDsPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calc_duration(self, sat_fgm: xr.DataArray):\n",
    "        return pdp.ApplyToRows(\n",
    "            lambda candidate: calc_candidate_duration(candidate, sat_fgm),\n",
    "            func_desc=\"calculating duration parameters\",\n",
    "        )\n",
    "\n",
    "    def calc_mva_features(self, sat_fgm):\n",
    "        return pdp.ApplyToRows(\n",
    "            lambda candidate: calc_candidate_mva_features(candidate, sat_fgm),\n",
    "            func_desc='calculating index \"q_mva\", \"BnOverB\" and \"dBOverB\"',\n",
    "        )\n",
    "\n",
    "    def calc_rotation_angle(self, sat_fgm):\n",
    "        return pdp.ColByFrameFunc(\n",
    "            \"rotation_angle\",\n",
    "            lambda df: calc_events_rotation_angle(df, sat_fgm),\n",
    "            func_desc=\"calculating rotation angle\",\n",
    "        )\n",
    "\n",
    "    def calc_normal_direction(self, sat_fgm):\n",
    "        return pdp.ColByFrameFunc(\n",
    "            \"normal_direction\",\n",
    "            lambda df: calc_events_normal_direction(df, sat_fgm),\n",
    "            func_desc=\"calculating normal direction\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ids_finder.utils.polars import convert_to_pd_dataframe, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_events(\n",
    "    candidates_pl: pl.DataFrame,  # potential candidates DataFrame\n",
    "    sat_fgm: xr.DataArray,  # satellite FGM data\n",
    "    data_resolution: timedelta,  # time resolution of the data\n",
    "    modin = True,\n",
    ") -> pl.DataFrame:\n",
    "    \"Process candidates DataFrame\"\n",
    "    \n",
    "    candidates = convert_to_pd_dataframe(candidates_pl, modin=modin)\n",
    "\n",
    "    id_pipelines = IDsPipeline()\n",
    "    candidates = id_pipelines.calc_duration(sat_fgm).apply(candidates)\n",
    "\n",
    "    ids = (\n",
    "        id_pipelines.calc_mva_features(sat_fgm)\n",
    "        + id_pipelines.calc_rotation_angle(sat_fgm)\n",
    "        + id_pipelines.calc_normal_direction(sat_fgm)\n",
    "    ).apply(\n",
    "        candidates.dropna()  # Remove candidates with NaN values)\n",
    "    )\n",
    "\n",
    "    if isinstance(ids, mpd.DataFrame):\n",
    "        ids = ids._to_pandas()\n",
    "    \n",
    "    return pl.DataFrame(ids)\n",
    "    # ValueError: Data type fixed_size_list[pyarrow] not supported by interchange protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obsolete codes because the timewindow now is overlapping. No need to consider where magnetic discontinuities happens in the boundary of one timewindow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_candidate_d_duration(candidate, data) -> pd.Series:\n",
    "    try:\n",
    "        if pd.isnull(candidate['d_tstart']) or pd.isnull(candidate['d_tstop']):\n",
    "            candidate_data = get_candidate_data(candidate, data, neighbor=1)\n",
    "            d_time = candidate['d_time']\n",
    "            threshold = candidate['threshold']\n",
    "            return calc_d_duration(candidate_data, d_time, threshold)\n",
    "        else:\n",
    "            return pandas.Series({\n",
    "                'd_tstart': candidate['d_tstart'],\n",
    "                'd_tstop': candidate['d_tstop'],\n",
    "            })\n",
    "    except Exception as e:\n",
    "        # logger.debug(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\")\n",
    "        print(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdp.ApplyToRows(\n",
    "#     lambda candidate: calc_candidate_d_duration(candidate, sat_fgm),\n",
    "#     func_desc=\"calculating duration parameters if needed\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrates candidate duration\n",
    "\n",
    "This calibration is based on the assumption that the magnetic discontinuity is symmetric around the center of time, which is not always true.\n",
    "\n",
    "So instead of calibrating the duration, we drop the events. \n",
    "- Cons: Might influence the statistics of occurrence rate, but \n",
    "- Pros: More robust results about the properties of the magnetic discontinuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_candidate_duration(\n",
    "    candidate: pd.Series, data:xr.DataArray, data_resolution, ratio = 3/4\n",
    "):\n",
    "    \"\"\"\n",
    "    Calibrates the candidate duration. \n",
    "    - If only one of 'd_tstart' or 'd_tstop' is provided, calculates the missing one based on the provided one and 'd_time'.\n",
    "    - Then if this is not enough points between 'd_tstart' and 'd_tstop', returns None for both.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - candidate (pd.Series): The input candidate with potential missing 'd_tstart' or 'd_tstop'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - pd.Series: The calibrated candidate.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_notnull = pd.notnull(candidate['d_tstart'])\n",
    "    stop_notnull = pd.notnull(candidate['d_tstop']) \n",
    "    \n",
    "    match start_notnull, stop_notnull:\n",
    "        case (True, True):\n",
    "            d_tstart = candidate['d_tstart']\n",
    "            d_tstop = candidate['d_tstop']\n",
    "        case (True, False):\n",
    "            d_tstart = candidate['d_tstart']\n",
    "            d_tstop = candidate['d_time'] -  candidate['d_tstart'] + candidate['d_time']\n",
    "        case (False, True):\n",
    "            d_tstart = candidate['d_time'] -  candidate['d_tstop'] + candidate['d_time']\n",
    "            d_tstop = candidate['d_tstop']\n",
    "        case (False, False):\n",
    "            return pandas.Series({\n",
    "                'd_tstart': None,\n",
    "                'd_tstop': None,\n",
    "            })\n",
    "    \n",
    "    duration = d_tstop - d_tstart\n",
    "    num_of_points_between = data.time.sel(time=slice(d_tstart, d_tstop)).count().item()\n",
    "    \n",
    "    if num_of_points_between <= (duration/data_resolution) * ratio:\n",
    "        d_tstart = None\n",
    "        d_tstop = None\n",
    "    \n",
    "    return pandas.Series({\n",
    "        'd_tstart': d_tstart,\n",
    "        'd_tstop': d_tstop,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_candidates_duration(candidates, sat_fgm, data_resolution):\n",
    "    # calibrate duration\n",
    "\n",
    "    calibrate_duration = pdp.ApplyToRows(\n",
    "        lambda candidate: calibrate_candidate_duration(\n",
    "            candidate, sat_fgm, data_resolution\n",
    "        ),\n",
    "        func_desc=\"calibrating duration parameters if needed\",\n",
    "    )\n",
    "\n",
    "    temp_candidates = candidates.loc[\n",
    "        lambda df: df[\"d_tstart\"].isnull() | df[\"d_tstop\"].isnull()\n",
    "    ]  # temp_candidates = candidates.query('d_tstart.isnull() | d_tstop.isnull()') # not implemented in `modin`\n",
    "\n",
    "    if not temp_candidates.empty:\n",
    "        temp_candidates_updated = calibrate_duration(sat_fgm, data_resolution).apply(\n",
    "            temp_candidates\n",
    "        )\n",
    "        candidates.update(temp_candidates_updated)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test parallelization\n",
    "\n",
    "\n",
    "Generally `mapply` and `modin` are the fastest. `xorbits` is expected to be the fastest but it is not and it is the slowest one.\n",
    "\n",
    "```python\n",
    "#| notest\n",
    "sat = 'jno'\n",
    "coord = 'se'\n",
    "cols = [\"BX\", \"BY\", \"BZ\"]\n",
    "tau = timedelta(seconds=60)\n",
    "data_resolution = timedelta(seconds=1)\n",
    "\n",
    "if True:\n",
    "    year = 2012\n",
    "    files = f'../data/{sat}_data_{year}.parquet'\n",
    "    output = f'../data/{sat}_candidates_{year}_tau_{tau.seconds}.parquet'\n",
    "\n",
    "    data = pl.scan_parquet(files).set_sorted('time').collect()\n",
    "\n",
    "    indices = compute_indices(data, tau)\n",
    "    # filter condition\n",
    "    sparse_num = tau / data_resolution // 3\n",
    "    filter_condition = filter_indices(sparse_num = sparse_num)\n",
    "\n",
    "    candidates = indices.filter(filter_condition).with_columns(pl_format_time(tau)).sort('time')\n",
    "    \n",
    "    data_c = compress_data_by_cands(data, candidates, tau)\n",
    "    sat_fgm = df2ts(data_c, cols, attrs={\"units\": \"nT\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "candidates_pd = candidates.to_pandas()\n",
    "candidates_modin = mpd.DataFrame(candidates_pd)\n",
    "# candidates_x = xpd.DataFrame(candidates_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: Test different libraries to parallelize the computation\n",
    "#| notest\n",
    "if True:\n",
    "    pdp_test = pdp.ApplyToRows(\n",
    "        lambda candidate: calc_candidate_duration(candidate, sat_fgm),  # fast a little bit\n",
    "        # lambda candidate: calc_duration(get_candidate_data_xr(candidate, sat_fgm)),\n",
    "        # lambda candidate: calc_duration(sat_fgm.sel(time=slice(candidate['tstart'], candidate['tstop']))),\n",
    "        func_desc=\"calculating duration parameters\",\n",
    "    )\n",
    "    \n",
    "    # process_events(candidates_modin, sat_fgm, sat_state, data_resolution)\n",
    "    \n",
    "    # ---\n",
    "    # successful cases\n",
    "    # ---\n",
    "    # candidates_pd.mapply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works, 4.2 secs\n",
    "    # candidates_pd.mapply(calc_candidate_duration, axis=1, data=sat_fgm) # this works, but a little bit slower, 6.7 secs\n",
    "    \n",
    "    # candidates_pd.apply(calc_candidate_duration, axis=1, data=sat_fgm) # Standard case: 24+s secs\n",
    "    # candidates_pd.swifter.apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 80 secs\n",
    "    # candidates_pd.swifter.set_dask_scheduler(scheduler=\"threads\").apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 60 secs\n",
    "    # candidates_modin.apply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works with ray, 6 secs # NOTE: can not work with dask\n",
    "    # candidates_x.apply(calc_candidate_duration, axis=1, data=sat_fgm) # 30 seconds\n",
    "    # pdp_test(candidates_modin) # this works, 8 secs\n",
    "    \n",
    "    # ---\n",
    "    # failed cases\n",
    "    # ---\n",
    "    # candidates_modin.apply(calc_candidate_duration, axis=1, data=sat_fgm) # AttributeError: 'DataFrame' object has no attribute 'sel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(task_dict, number=1):\n",
    "    results = {}\n",
    "    for name, (data, task) in task_dict.items():\n",
    "        try:\n",
    "            time_taken = timeit.timeit(\n",
    "                lambda: task(data),\n",
    "                number=number\n",
    "            )\n",
    "            results[name] = time_taken / number\n",
    "        except Exception as e:\n",
    "            results[name] = str(e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "\n",
    "def benchmark_results(results, sat_fgm):\n",
    "    func = partial(calc_candidate_duration, data=sat_fgm)\n",
    "    task_dict = {\n",
    "        'pandas': (candidates_pd, lambda _: _.apply(func, axis=1)),\n",
    "        'pandas-mapply': (candidates_pd, lambda _: _.mapply(func, axis=1)),\n",
    "        'modin': (candidates_modin, lambda _: _.apply(func, axis=1)),\n",
    "        # 'xorbits': (candidates_x, lambda _: _.apply(func, axis=1)),\n",
    "    }\n",
    "\n",
    "    results = benchmark(task_dict)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cool_planet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
