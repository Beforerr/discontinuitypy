{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: ID properties\n",
    "subtitle: Full feature extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core/propeties\n",
    "# | export\n",
    "# | code-summary: \"Import all the packages needed for the project\"\n",
    "import polars as pl\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import modin.pandas as pd\n",
    "    from modin.config import ProgressBar\n",
    "\n",
    "    ProgressBar.enable()\n",
    "except ImportError:\n",
    "    import pandas as pd\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from discontinuitypy.propeties.duration import calc_duration\n",
    "from discontinuitypy.propeties.mva import calc_mva_features_all\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_data_at_times(data: xr.DataArray, times) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Select data at specified times.\n",
    "    \"\"\"\n",
    "    # Use xarray's selection capability if data supports it\n",
    "    return data.sel(time=times, method=\"nearest\").to_numpy()\n",
    "\n",
    "\n",
    "def select_data_by_timerange(data: xr.DataArray, tstart, tstop, neighbor: int = 0):\n",
    "    duration = tstop - tstart\n",
    "    offset = neighbor * duration\n",
    "    timerange = slice(tstart - offset, tstop + offset)\n",
    "    return data.sel(time=timerange)\n",
    "\n",
    "\n",
    "def get_candidate_data(candidate: dict, data: xr.DataArray, **kwargs):\n",
    "    return select_data_by_timerange(\n",
    "        data, candidate[\"tstart\"], candidate[\"tstop\"], **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def get_candidates(candidates: pd.DataFrame, candidate_type=None, num: int = 4):\n",
    "    if candidate_type is not None:\n",
    "        _candidates = candidates[candidates[\"type\"] == candidate_type]\n",
    "    else:\n",
    "        _candidates = candidates\n",
    "\n",
    "    # Sample a specific number of candidates if num is provided and it's less than the total number\n",
    "    if num < len(_candidates):\n",
    "        logger.info(\n",
    "            f\"Sampling {num} {candidate_type} candidates out of {len(_candidates)}\"\n",
    "        )\n",
    "        return _candidates.sample(num)\n",
    "    else:\n",
    "        return _candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "def ld2dl(listdict: list[dict], func=np.array):\n",
    "    \"\"\"Convert a list of dictionaries to a dictionary of lists.\"\"\"\n",
    "    return {key: func([result[key] for result in listdict]) for key in listdict[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_candidate_duration(candidate, data, **kwargs):\n",
    "    candidate_data = get_candidate_data(candidate, data)\n",
    "    return calc_duration(candidate_data, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_events_duration(df: pl.DataFrame, data, tr_cols=[\"tstart\", \"tstop\"], **kwargs):\n",
    "    # TODO: Add support for parallel processing\n",
    "    results = [\n",
    "        calc_duration(select_data_by_timerange(data, row[0], row[1]), **kwargs)\n",
    "        for row in df.select(tr_cols).iter_rows()\n",
    "    ]\n",
    "    return df.with_columns(**ld2dl(results)).drop_nulls()\n",
    "\n",
    "\n",
    "def calc_events_mva_features(\n",
    "    df: pl.DataFrame,\n",
    "    data: xr.DataArray,\n",
    "    method: Literal[\"fit\", \"derivative\"],\n",
    "    tr_cols=[\"t.d_start\", \"t.d_end\"],\n",
    "    **kwargs,\n",
    "):\n",
    "    results = [\n",
    "        calc_mva_features_all(\n",
    "            select_data_by_timerange(data, row[0], row[1]), method=method, **kwargs\n",
    "        )\n",
    "        for row in df.select(tr_cols).iter_rows()\n",
    "    ]\n",
    "    return df.with_columns(**ld2dl(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_normal_direction(v1, v2, normalize=True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the normal direction of two vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v1 : array_like\n",
    "        The first vector(s).\n",
    "    v2 : array_like\n",
    "        The second vector(s).\n",
    "    \"\"\"\n",
    "    c = np.cross(v1, v2)\n",
    "    return c / np.linalg.norm(c, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_events_normal_direction(events: pl.DataFrame, data: xr.DataArray, name=\"k\"):\n",
    "    \"\"\"\n",
    "    Computes the normal directions(s) at two different time steps.\n",
    "    \"\"\"\n",
    "    tstart = events[\"t.d_start\"].to_numpy()\n",
    "    tstop = events[\"t.d_end\"].to_numpy()\n",
    "\n",
    "    vecs_before = get_data_at_times(data, tstart)\n",
    "    vecs_after = get_data_at_times(data, tstop)\n",
    "\n",
    "    normal_directions = calc_normal_direction(vecs_before, vecs_after)\n",
    "    # need to convert to list first, as only 1D array is supported\n",
    "    return events.with_columns(pl.Series(name, normal_directions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def calc_events_vec_change(events: pl.DataFrame, data: xr.DataArray, name=\"dB\"):\n",
    "    \"\"\"\n",
    "    Utils function to calculate features related to the change of the magnetic field\n",
    "    \"\"\"\n",
    "    tstart = events[\"t.d_start\"].to_numpy()\n",
    "    tstop = events[\"t.d_end\"].to_numpy()\n",
    "\n",
    "    vecs_before = get_data_at_times(data, tstart)\n",
    "    vecs_after = get_data_at_times(data, tstop)\n",
    "    dvecs = vecs_after - vecs_before\n",
    "\n",
    "    return events.with_columns(pl.Series(name, dvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def process_events(\n",
    "    events: pl.DataFrame,  # potential candidates DataFrame\n",
    "    data: xr.DataArray,\n",
    "    method: Literal[\"fit\", \"derivative\"] = \"fit\",\n",
    "    **kwargs,\n",
    "):\n",
    "    \"Process candidates DataFrame\"\n",
    "\n",
    "    if method == \"fit\":\n",
    "        duration_method = \"distance\"\n",
    "        duration_expr = pl.col(\"fit.vars.sigma\") * 2\n",
    "    else:\n",
    "        duration_method = \"derivative\"\n",
    "        duration_expr = (\n",
    "            pl.col(\"t.d_end\") - pl.col(\"t.d_start\")\n",
    "        ).dt.total_nanoseconds() / 1e9\n",
    "\n",
    "    return (\n",
    "        events.pipe(calc_events_duration, data=data, method=duration_method)\n",
    "        .pipe(calc_events_mva_features, data=data, method=method)\n",
    "        .pipe(calc_events_vec_change, data=data, name=\"dB\")\n",
    "        .pipe(calc_events_normal_direction, data=data, name=\"k\")\n",
    "    ).with_columns(duration=duration_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test parallelization\n",
    "\n",
    "\n",
    "Generally `mapply` and `modin` are the fastest. `xorbits` is expected to be the fastest but it is not and it is the slowest one.\n",
    "\n",
    "```python\n",
    "#| notest\n",
    "sat = 'jno'\n",
    "coord = 'se'\n",
    "cols = [\"BX\", \"BY\", \"BZ\"]\n",
    "tau = timedelta(seconds=60)\n",
    "data_resolution = timedelta(seconds=1)\n",
    "\n",
    "if True:\n",
    "    year = 2012\n",
    "    files = f'../data/{sat}_data_{year}.parquet'\n",
    "    output = f'../data/{sat}_candidates_{year}_tau_{tau.seconds}.parquet'\n",
    "\n",
    "    data = pl.scan_parquet(files).set_sorted('time').collect()\n",
    "\n",
    "    indices = compute_indices(data, tau)\n",
    "    # filter condition\n",
    "    sparse_num = tau / data_resolution // 3\n",
    "    filter_condition = filter_indices(sparse_num = sparse_num)\n",
    "\n",
    "    candidates = indices.filter(filter_condition).with_columns(pl_format_time(tau)).sort('time')\n",
    "    \n",
    "    data_c = compress_data_by_events(data, candidates, tau)\n",
    "    sat_fgm = df2ts(data_c, cols, attrs={\"units\": \"nT\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-summary: Test different libraries to parallelize the computation\n",
    "# | notest\n",
    "def test_parallelization(candidates, sat_fgm):\n",
    "    # process_events(candidates_modin, sat_fgm, sat_state, data_resolution)\n",
    "\n",
    "    # ---\n",
    "    # successful cases\n",
    "    # ---\n",
    "    # candidates_pd.mapply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works, 4.2 secs\n",
    "    # candidates_pd.mapply(calc_candidate_duration, axis=1, data=sat_fgm) # this works, but a little bit slower, 6.7 secs\n",
    "\n",
    "    # candidates_pd.apply(calc_candidate_duration, axis=1, data=sat_fgm) # Standard case: 24+s secs\n",
    "    # candidates_pd.swifter.apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 80 secs\n",
    "    # candidates_pd.swifter.set_dask_scheduler(scheduler=\"threads\").apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 60 secs\n",
    "    # candidates_modin.apply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works with ray, 6 secs # NOTE: can not work with dask\n",
    "    # candidates_x.apply(calc_candidate_duration, axis=1, data=sat_fgm) # 30 seconds\n",
    "    # ---\n",
    "    # failed cases\n",
    "    # ---\n",
    "    # candidates_modin.apply(calc_candidate_duration, axis=1, data=sat_fgm) # AttributeError: 'DataFrame' object has no attribute 'sel'\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(task_dict, number=1):\n",
    "    results = {}\n",
    "    for name, (data, task) in task_dict.items():\n",
    "        try:\n",
    "            time_taken = timeit.timeit(lambda: task(data), number=number)\n",
    "            results[name] = time_taken / number\n",
    "        except Exception as e:\n",
    "            results[name] = str(e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "import modin.pandas as mpd\n",
    "\n",
    "\n",
    "def benchmark_results(candidates, sat_fgm):\n",
    "    candidates_pd = candidates.to_pandas()\n",
    "    candidates_modin = mpd.DataFrame(candidates_pd)\n",
    "    # candidates_x = xpd.DataFrame(candidates_pd)\n",
    "\n",
    "    func = partial(calc_candidate_duration, data=sat_fgm)\n",
    "    task_dict = {\n",
    "        \"pandas\": (candidates_pd, lambda _: _.apply(func, axis=1)),\n",
    "        \"pandas-mapply\": (candidates_pd, lambda _: _.mapply(func, axis=1)),\n",
    "        \"modin\": (candidates_modin, lambda _: _.apply(func, axis=1)),\n",
    "        # 'xorbits': (candidates_x, lambda _: _.apply(func, axis=1)),\n",
    "    }\n",
    "\n",
    "    results = benchmark(task_dict)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
