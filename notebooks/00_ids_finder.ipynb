{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Finding magnetic discontinuities\n",
    "order: 0\n",
    "---\n",
    "\n",
    "It can be divided into two parts:\n",
    "\n",
    "1. Finding the discontinuities, see [this notebook](./01_ids_detection.ipynb)\n",
    "    - Corresponding to limited feature extraction / anomaly detection\n",
    "2. Calculating the properties of the discontinuities, see [this notebook](./02_ids_properties.ipynb)\n",
    "    - One can use higher time resolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/18/23 10:15:25] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook    <a href=\"file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         mode. Use `tqdm.tqdm` instead to force console mode <span style=\"font-weight: bold\">(</span>e.g. in jupyter   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         console<span style=\"font-weight: bold\">)</span>                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/18/23 10:15:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook    \u001b]8;id=256656;file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=668127;file:///Users/zijin/miniforge3/envs/cool_planet/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         mode. Use `tqdm.tqdm` instead to force console mode \u001b[1m(\u001b[0me.g. in jupyter   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         console\u001b[1m)\u001b[0m                                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "#| code-summary: \"Import all the packages needed for the project\"\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "from ids_finder.utils.basic import *\n",
    "import polars as pl\n",
    "import xarray as xr\n",
    "from ids_finder.core.detection import *\n",
    "from ids_finder.core.propeties import *\n",
    "\n",
    "try:\n",
    "    import modin.pandas as pd\n",
    "    import modin.pandas as mpd\n",
    "    from modin.config import ProgressBar\n",
    "    ProgressBar.enable()\n",
    "except ImportError:\n",
    "    import pandas as pd\n",
    "import pandas\n",
    "    \n",
    "import numpy as np\n",
    "from xarray_einstats import linalg\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "import pdpipe as pdp\n",
    "\n",
    "from typing import Any, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Stages\n",
    "\n",
    "- [ ] Smoothing\n",
    "- [ ] Interpolating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def filter_indices(\n",
    "    df: pl.DataFrame | pl.LazyFrame,\n",
    "    index_std_threshold=2,\n",
    "    index_fluc_threshold=1,\n",
    "    index_diff_threshold=0.1,\n",
    "    sparse_num=15,\n",
    ") -> pl.DataFrame | pl.LazyFrame:\n",
    "    # filter indices to get possible IDs\n",
    "\n",
    "    return df.filter(\n",
    "        pl.col(\"index_std\") > index_std_threshold,\n",
    "        pl.col(\"index_fluctuation\") > index_fluc_threshold,\n",
    "        pl.col(\"index_diff\") > index_diff_threshold,\n",
    "        pl.col(\"index_std\").is_finite(), # for cases where neighboring groups have std=0\n",
    "        pl.col(\"count\") > sparse_num, \n",
    "        pl.col(\"count_prev\") > sparse_num, # filter out sparse intervals, which may give unreasonable results.\n",
    "        pl.col(\"count_next\") > sparse_num, # filter out sparse intervals, which may give unreasonable results.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pdpipe.util import out_of_place_col_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patch `pdp.ApplyToRows` to work with `modin` and `xorbits` DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _transform(self: pdp.ApplyToRows, X, verbose):\n",
    "    new_cols = X.apply(self._func, axis=1)\n",
    "    if isinstance(new_cols, (pd.Series, pandas.Series)):\n",
    "        loc = len(X.columns)\n",
    "        if self._follow_column:\n",
    "            loc = X.columns.get_loc(self._follow_column) + 1\n",
    "        return out_of_place_col_insert(\n",
    "            X=X, series=new_cols, loc=loc, column_name=self._colname\n",
    "        )\n",
    "    if isinstance(new_cols, (mpd.DataFrame, pandas.DataFrame)):\n",
    "        sorted_cols = sorted(list(new_cols.columns))\n",
    "        new_cols = new_cols[sorted_cols]\n",
    "        if self._follow_column:\n",
    "            inter_X = X\n",
    "            loc = X.columns.get_loc(self._follow_column) + 1\n",
    "            for colname in new_cols.columns:\n",
    "                inter_X = out_of_place_col_insert(\n",
    "                    X=inter_X,\n",
    "                    series=new_cols[colname],\n",
    "                    loc=loc,\n",
    "                    column_name=colname,\n",
    "                )\n",
    "                loc += 1\n",
    "            return inter_X\n",
    "        assign_map = {\n",
    "            colname: new_cols[colname] for colname in new_cols.columns\n",
    "        }\n",
    "        return X.assign(**assign_map)\n",
    "    raise TypeError(  # pragma: no cover\n",
    "        \"Unexpected type generated by applying a function to a DataFrame.\"\n",
    "        \" Only Series and DataFrame are allowed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_candidate_mva_features(candidate, data: xr.DataArray):\n",
    "\n",
    "    output_names = [\"Vl_x\", \"Vl_y\", \"Vl_z\", \"eig0\", \"eig1\", \"eig2\", 'Q_mva', 'b_mag', 'b_n', 'db_mag', 'bn_over_b', 'db_over_b', 'db_over_b_max', 'db_l', 'db_m', 'db_n']\n",
    "    results = mva_features(\n",
    "        data.sel(time=slice(candidate[\"d_tstart\"], candidate[\"d_tstop\"])).to_numpy()\n",
    "    )\n",
    "    \n",
    "    return pandas.Series(results, output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_dataframe(\n",
    "    data: pl.DataFrame | pl.LazyFrame # orignal Dataframe\n",
    ")->pd.DataFrame:\n",
    "    \"convert data into a pandas/modin DataFrame\"\n",
    "    if isinstance(data, pl.LazyFrame):\n",
    "        data = data.collect().to_pandas(use_pyarrow_extension_array=True)\n",
    "    if isinstance(data, pl.DataFrame):\n",
    "        data = data.to_pandas(use_pyarrow_extension_array=True)\n",
    "    if not isinstance(data, pd.DataFrame):  # `modin` supports\n",
    "        data = pd.DataFrame(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipelines` Class for processing IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class IDsPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calc_duration(self, sat_fgm: xr.DataArray):\n",
    "        return pdp.ApplyToRows(\n",
    "            lambda candidate: calc_candidate_duration(candidate, sat_fgm),\n",
    "            func_desc=\"calculating duration parameters\",\n",
    "        )\n",
    "\n",
    "    def calibrate_duration(self, sat_fgm, data_resolution):\n",
    "        return pdp.ApplyToRows(\n",
    "            lambda candidate: calibrate_candidate_duration(\n",
    "                candidate, sat_fgm, data_resolution\n",
    "            ),\n",
    "            func_desc=\"calibrating duration parameters if needed\",\n",
    "        )\n",
    "\n",
    "    def calc_mva_features(self, sat_fgm):\n",
    "        return pdp.ApplyToRows(\n",
    "            lambda candidate: calc_candidate_mva_features(candidate, sat_fgm),\n",
    "            func_desc='calculating index \"q_mva\", \"BnOverB\" and \"dBOverB\"',\n",
    "        )\n",
    "\n",
    "    def calc_rotation_angle(self, sat_fgm):\n",
    "        return pdp.ColByFrameFunc(\n",
    "            \"rotation_angle\",\n",
    "            lambda df: calc_candidate_rotation_angle(df, sat_fgm),\n",
    "            func_desc=\"calculating rotation angle\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes that the candidates only require a small portion of the data so we can compress the data to speed up the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def compress_data_by_cands(\n",
    "    data: pl.DataFrame, candidates: pl.DataFrame, tau: timedelta\n",
    "):\n",
    "    \"\"\"Compress the data for parallel processing\"\"\"\n",
    "    ttstarts = candidates[\"tstart\"] - tau\n",
    "    ttstops = candidates[\"tstop\"] + tau\n",
    "\n",
    "    ttstarts_index = data[\"time\"].search_sorted(ttstarts)\n",
    "    ttstops_index = data[\"time\"].search_sorted(ttstops)\n",
    "\n",
    "    indices = np.concatenate(\n",
    "        [\n",
    "            np.arange(ttstart_index, ttstop_index + 1)\n",
    "            for ttstart_index, ttstop_index in zip(ttstarts_index, ttstops_index)\n",
    "        ]\n",
    "    )  # faster than `pl.arange`\n",
    "    indices_unique = (\n",
    "        pl.Series(indices).unique().sort()\n",
    "    )  # faster than `np.unique(index)`\n",
    "    return data[indices_unique]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def sort_df(df: pl.DataFrame, col=\"time\"):\n",
    "    if df.get_column(col).is_sorted():\n",
    "        return df.set_sorted(col)\n",
    "    else:\n",
    "        return df.sort(col)\n",
    "\n",
    "\n",
    "def process_candidates(\n",
    "    candidates_pl: pl.DataFrame,  # potential candidates DataFrame\n",
    "    sat_fgm: xr.DataArray,  # satellite FGM data\n",
    "    data_resolution: timedelta,  # time resolution of the data\n",
    ") -> pl.DataFrame:\n",
    "    \"Process candidates DataFrame\"\n",
    "    \n",
    "    candidates = convert_to_dataframe(candidates_pl)\n",
    "\n",
    "    id_pipelines = IDsPipeline()\n",
    "    candidates = id_pipelines.calc_duration(sat_fgm).apply(candidates)\n",
    "\n",
    "    # calibrate duration\n",
    "    temp_candidates = candidates.loc[\n",
    "        lambda df: df[\"d_tstart\"].isnull() | df[\"d_tstop\"].isnull()\n",
    "    ]  # temp_candidates = candidates.query('d_tstart.isnull() | d_tstop.isnull()') # not implemented in `modin`\n",
    "\n",
    "    if not temp_candidates.empty:\n",
    "        temp_candidates_updated = id_pipelines.calibrate_duration(\n",
    "            sat_fgm, data_resolution\n",
    "        ).apply(temp_candidates)\n",
    "        candidates.update(temp_candidates_updated)\n",
    "\n",
    "    ids = (\n",
    "        id_pipelines.calc_mva_features(sat_fgm)\n",
    "        + id_pipelines.calc_rotation_angle(sat_fgm)\n",
    "    ).apply(\n",
    "        candidates.dropna()  # Remove candidates with NaN values)\n",
    "    )\n",
    "\n",
    "    if isinstance(ids, mpd.DataFrame):\n",
    "        ids = ids._to_pandas()\n",
    "    if isinstance(ids, pandas.DataFrame):\n",
    "        ids_pl = pl.DataFrame(ids)\n",
    "\n",
    "    return ids_pl.pipe(sort_df, col=\"d_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def ids_finder(data: pl.LazyFrame, tau: float, params: dict):\n",
    "    tau = timedelta(seconds=tau)\n",
    "    ts = timedelta(seconds=params[\"time_resolution\"])\n",
    "    bcols = params.get(\"bcols\", [\"B_x\", \"B_y\", \"B_z\"])\n",
    "    data = data.sort(\"time\").collect()\n",
    "\n",
    "    # get candidates\n",
    "    indices = compute_indices(data, tau, bcols)\n",
    "    sparse_num = tau / ts // 3\n",
    "    candidates = indices.pipe(filter_indices, sparse_num=sparse_num).pipe(\n",
    "        pl_format_time, tau\n",
    "    )\n",
    "\n",
    "    data_c = compress_data_by_cands(data, candidates, tau)\n",
    "    sat_fgm = df2ts(data_c, bcols)\n",
    "    ids = process_candidates(candidates, sat_fgm, ts)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def extract_features(\n",
    "    partitioned_input: Dict[str, Callable], tau: float, params\n",
    ") -> pl.DataFrame:\n",
    "    ids = pl.concat(\n",
    "        [\n",
    "            ids_finder(partition_load(), tau, params)\n",
    "            for partition_load in partitioned_input.values()\n",
    "        ]\n",
    "    )\n",
    "    return ids.unique([\"d_time\", \"d_tstart\", \"d_tstop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Generally `mapply` and `modin` are the fastest. `xorbits` is expected to be the fastest but it is not and it is the slowest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "sat = 'jno'\n",
    "coord = 'se'\n",
    "cols = [\"BX\", \"BY\", \"BZ\"]\n",
    "tau = timedelta(seconds=60)\n",
    "data_resolution = timedelta(seconds=1)\n",
    "\n",
    "if True:\n",
    "    year = 2012\n",
    "    files = f'../data/{sat}_data_{year}.parquet'\n",
    "    output = f'../data/{sat}_candidates_{year}_tau_{tau.seconds}.parquet'\n",
    "\n",
    "    data = pl.scan_parquet(files).set_sorted('time').collect()\n",
    "\n",
    "    indices = compute_indices(data, tau)\n",
    "    # filter condition\n",
    "    sparse_num = tau / data_resolution // 3\n",
    "    filter_condition = filter_indices(sparse_num = sparse_num)\n",
    "\n",
    "    candidates = indices.filter(filter_condition).with_columns(pl_format_time(tau)).sort('time')\n",
    "    \n",
    "    data_c = compress_data_by_cands(data, candidates, tau)\n",
    "    sat_fgm = df2ts(data_c, cols, attrs={\"units\": \"nT\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "candidates_pd = candidates.to_pandas()\n",
    "candidates_modin = mpd.DataFrame(candidates_pd)\n",
    "# candidates_x = xpd.DataFrame(candidates_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: Test different libraries to parallelize the computation\n",
    "#| notest\n",
    "if True:\n",
    "    pdp_test = pdp.ApplyToRows(\n",
    "        lambda candidate: calc_candidate_duration(candidate, sat_fgm),  # fast a little bit\n",
    "        # lambda candidate: calc_duration(get_candidate_data_xr(candidate, sat_fgm)),\n",
    "        # lambda candidate: calc_duration(sat_fgm.sel(time=slice(candidate['tstart'], candidate['tstop']))),\n",
    "        func_desc=\"calculating duration parameters\",\n",
    "    )\n",
    "    \n",
    "    # process_candidates(candidates_modin, sat_fgm, sat_state, data_resolution)\n",
    "    \n",
    "    # ---\n",
    "    # successful cases\n",
    "    # ---\n",
    "    # candidates_pd.mapply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works, 4.2 secs\n",
    "    # candidates_pd.mapply(calc_candidate_duration, axis=1, data=sat_fgm) # this works, but a little bit slower, 6.7 secs\n",
    "    \n",
    "    # candidates_pd.apply(calc_candidate_duration, axis=1, data=sat_fgm) # Standard case: 24+s secs\n",
    "    # candidates_pd.swifter.apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 80 secs\n",
    "    # candidates_pd.swifter.set_dask_scheduler(scheduler=\"threads\").apply(calc_candidate_duration, axis=1, data=sat_fgm) # this works with dask, 60 secs\n",
    "    # candidates_modin.apply(lambda candidate: calc_candidate_duration(candidate, sat_fgm), axis=1) # this works with ray, 6 secs # NOTE: can not work with dask\n",
    "    # candidates_x.apply(calc_candidate_duration, axis=1, data=sat_fgm) # 30 seconds\n",
    "    # pdp_test(candidates_modin) # this works, 8 secs\n",
    "    \n",
    "    # ---\n",
    "    # failed cases\n",
    "    # ---\n",
    "    # candidates_modin.apply(calc_candidate_duration, axis=1, data=sat_fgm) # AttributeError: 'DataFrame' object has no attribute 'sel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tsflex.features import MultipleFeatureDescriptors, FeatureCollection\n",
    "\n",
    "# from tsflex.features.integrations import catch22_wrapper\n",
    "# from pycatch22 import catch22_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau_pd = pd.Timedelta(tau)\n",
    "\n",
    "# catch22_feats = MultipleFeatureDescriptors(\n",
    "#     functions=catch22_wrapper(catch22_all),\n",
    "#     series_names=bcols,  # list of signal names\n",
    "#     windows = tau_pd, strides=tau_pd/2,\n",
    "# )\n",
    "\n",
    "# fc = FeatureCollection(catch22_feats)\n",
    "# features = fc.calculate(data, return_df=True)  # calculate the features on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_pl = pl.DataFrame(features.reset_index()).sort('time')\n",
    "# df = candidates_pl.join_asof(features_pl, on='time').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"JUNO Candidates Report\")\n",
    "# profile.to_file(\"jno.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(task_dict, number=1):\n",
    "    results = {}\n",
    "    for name, (data, task) in task_dict.items():\n",
    "        try:\n",
    "            time_taken = timeit.timeit(\n",
    "                lambda: task(data),\n",
    "                number=number\n",
    "            )\n",
    "            results[name] = time_taken / number\n",
    "        except Exception as e:\n",
    "            results[name] = str(e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "func = lambda candidate: calc_candidate_duration(candidate, sat_fgm)\n",
    "task_dict = {\n",
    "    'pandas': (candidates_pd, lambda _: _.apply(func, axis=1)),\n",
    "    'pandas-mapply': (candidates_pd, lambda _: _.mapply(func, axis=1)),\n",
    "    'modin': (candidates_modin, lambda _: _.apply(func, axis=1)),\n",
    "    # 'xorbits': (candidates_x, lambda _: _.apply(func, axis=1)),\n",
    "}\n",
    "\n",
    "results = benchmark(task_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "\n",
    "1. Feature engineering\n",
    "2. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obsolete codes because the timewindow now is overlapping. No need to consider where magnetic discontinuities happens in the boundary of one timewindow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_candidate_d_duration(candidate, data) -> pd.Series:\n",
    "    try:\n",
    "        if pd.isnull(candidate['d_tstart']) or pd.isnull(candidate['d_tstop']):\n",
    "            candidate_data = get_candidate_data(candidate, data, neighbor=1)\n",
    "            d_time = candidate['d_time']\n",
    "            threshold = candidate['threshold']\n",
    "            return calc_d_duration(candidate_data, d_time, threshold)\n",
    "        else:\n",
    "            return pandas.Series({\n",
    "                'd_tstart': candidate['d_tstart'],\n",
    "                'd_tstop': candidate['d_tstop'],\n",
    "            })\n",
    "    except Exception as e:\n",
    "        # logger.debug(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\")\n",
    "        print(f\"Error for candidate {candidate} at {candidate['time']}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "pdp.ApplyToRows(\n",
    "    lambda candidate: calc_candidate_d_duration(candidate, sat_fgm),\n",
    "    func_desc=\"calculating duration parameters if needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsolete codes for xarray related calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vec_mean_mag(vec: xr.DataArray):\n",
    "    return linalg.norm(vec, dims=\"v_dim\").mean(dim=\"time\")\n",
    "\n",
    "\n",
    "def calc_vec_std(vec: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Computes the standard deviation of a vector.\n",
    "    \"\"\"\n",
    "    return linalg.norm(vec.std(dim=\"time\"), dims=\"v_dim\")\n",
    "\n",
    "\n",
    "def calc_vec_relative_diff(vec: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Computes the relative difference between the last and first elements of a vector.\n",
    "    \"\"\"\n",
    "    dvec = vec.isel(time=-1) - vec.isel(time=0)\n",
    "    return linalg.norm(dvec, dims=\"v_dim\") / linalg.norm(vec, dims=\"v_dim\").mean(\n",
    "        dim=\"time\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `process_candidates`\n",
    "Assign coordinates using `Dataframe.apply` is not optimized, quite slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_candidates(\n",
    "    candidates: pd.DataFrame, # potential candidates DataFrame\n",
    "    sat_fgm: xr.DataArray, # satellite FGM data\n",
    "    sat_state: xr.DataArray, # satellite state data\n",
    "    data_resolution: timedelta, # time resolution of the data\n",
    ") -> pd.DataFrame: # processed candidates DataFrame\n",
    "    id_pipelines = IDsPipeline()\n",
    "\n",
    "    candidates = id_pipelines.calc_duration(sat_fgm).apply(candidates)\n",
    "\n",
    "    # calibrate duration\n",
    "    temp_candidates = candidates.loc[\n",
    "        lambda df: df[\"d_tstart\"].isnull() | df[\"d_tstop\"].isnull()\n",
    "    ]  # temp_candidates = candidates.query('d_tstart.isnull() | d_tstop.isnull()') # not implemented in `modin`\n",
    "\n",
    "    if not temp_candidates.empty:\n",
    "        candidates.update(\n",
    "            id_pipelines.calibrate_duration(sat_fgm, data_resolution).apply(\n",
    "                temp_candidates\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ids = (\n",
    "        id_pipelines.calc_mva_features(sat_fgm)\n",
    "        + id_pipelines.calc_rotation_angle(sat_fgm)\n",
    "        + id_pipelines.assign_coordinates(sat_state)\n",
    "    ).apply(\n",
    "        candidates.dropna()  # Remove candidates with NaN values)\n",
    "    )\n",
    "\n",
    "    return ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
